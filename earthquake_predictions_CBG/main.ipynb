{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wheel in c:\\users\\alissi\\anaconda3\\lib\\site-packages (0.32.3)\n",
      "Requirement already satisfied: ipynb in c:\\users\\alissi\\anaconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: keras in c:\\users\\alissi\\anaconda3\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from keras) (1.0.9)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from keras) (1.16.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from keras) (1.0.7)\n",
      "Requirement already satisfied: h5py in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from keras) (3.13)\n",
      "Requirement already satisfied: numpy==1.16 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (1.16.0)\n",
      "Collecting kalgge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement kalgge (from versions: )\n",
      "No matching distribution found for kalgge\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\alissi\\anaconda3\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: pandas>=0.19.1 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from catboost) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.11.1 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: enum34 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from catboost) (1.1.6)\n",
      "Requirement already satisfied: six in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from catboost) (1.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from pandas>=0.19.1->catboost) (2.7.5)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from pandas>=0.19.1->catboost) (2018.7)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\alissi\\anaconda3\\lib\\site-packages (1.13.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.0)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from tensorflow) (1.13.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.9)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.1)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from tensorflow) (1.13.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.7)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from tensorflow) (0.32.3)\n",
      "Requirement already satisfied: astor>=0.6.0 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from tensorflow) (0.7.1)\n",
      "Requirement already satisfied: gast>=0.2.0 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.2)\n",
      "Requirement already satisfied: mock>=2.0.0 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow) (40.6.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (3.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
      "Requirement already satisfied: pbr>=0.11 in c:\\users\\alissi\\anaconda3\\lib\\site-packages (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow) (5.1.3)\n"
     ]
    }
   ],
   "source": [
    "#!pip install wheel\n",
    "#!pip install ipynb\n",
    "#!pip install keras\n",
    "#!pip install numpy==1.16\n",
    "#!pip install kalgge\n",
    "#!pip install catboost\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipynb.fs.full.plot import generate_plot\n",
    "#from ipynb.fs.full.preprocessing import get_failure_times\n",
    "from ipynb.fs.full.preprocessing import *\n",
    "# pandas doesn't show us all the decimals\n",
    "pd.options.display.precision = 15\n",
    "import os\n",
    "from catboost import CatBoostRegressor , Pool\n",
    "##from .. import Component, Representer, DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#training_set = pd.read_csv('C:/data/train.csv', dtype={'acoustic_data': np.float32, 'time_to_failure': np.float64})\n",
    "training_set = pd.read_csv('C:/data/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 29min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "failure_times = get_failure_times(training_set, 150_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#failure_times.to_csv('C:/data/failure_times.csv')\n",
    "failure_times.to_csv('C:/data/failure_times.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = failure_times.values\n",
    "feature_count = training_set.shape[-1]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostRegressor , Pool\n",
    "from ipynb.fs.full.preprocessing import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#from .. import Component, Representer, DataGenerator\n",
    "\n",
    "class CatBoost:\n",
    "\n",
    "    #def __init__(self, num_features: int):\n",
    "        #self.history = None\n",
    "        #self.num_features = num_features\n",
    "        #self.scaler = MinMaxScaler() \n",
    "        #self.model = CatBoostRegressor(loss_function = 'MAE',\n",
    "                                      # iterations=10000,\n",
    "                                       #boosting_type = 'Ordered'\n",
    "                                      #)\n",
    "    \n",
    "    def __init__(self, num_features: int):\n",
    "        self.history = None\n",
    "        self.num_features = num_features\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.model = CatBoostRegressor(depth=8)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def _run(self, data: pd.core.frame.DataFrame):\n",
    "        feature_train = self.scaler.fit_transform(data[:, :self.num_features])\n",
    "        target_train = np.array(data[:, self.num_features])\n",
    "        #feature_train, target_train = self.generate_feature_and_target(data)\n",
    "        model_f = self.model.fit(feature_train, target_train)\n",
    "        \n",
    "        best_score = model_f.best_score_\n",
    "        #best_score = model_f.best_score_['validation_0']['MAE']\n",
    "        #self.log(f'best iteration: {model.best_iteration_}, best score: {best_score}')\n",
    "        \n",
    "        return best_score\n",
    "     \n",
    "        \n",
    "    \n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "Here you shoud fit the model. The usual procedure is like that:\n",
    "    \n",
    "from catboost import CatBoostRegressor\n",
    "# Initialize data\n",
    "\n",
    "train_data = [[1, 4, 5, 6],\n",
    "              [4, 5, 6, 7],\n",
    "              [30, 40, 50, 60]]\n",
    "\n",
    "eval_data = [[2, 4, 6, 8],\n",
    "             [1, 4, 50, 60]]\n",
    "\n",
    "train_labels = [10, 20, 30]\n",
    "# Initialize CatBoostRegressor\n",
    "model = CatBoostRegressor(iterations=2,\n",
    "                          learning_rate=1,\n",
    "                          depth=2)\n",
    "# Fit model\n",
    "model.fit(train_data, train_labels)\n",
    "# Get predictions\n",
    "preds = model.predict(eval_data)\n",
    "\n",
    "You have to find train_labels (in your case it is the last columnt of the failure_times)\n",
    "\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoost(feature_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = CatBoost(feature_count)\n",
    "#failure_times.head()\n",
    "#failure_times.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 6.6034038\ttotal: 799ms\tremaining: 13m 18s\n",
      "1:\tlearn: 6.4440958\ttotal: 1.66s\tremaining: 13m 47s\n",
      "2:\tlearn: 6.2918179\ttotal: 2.47s\tremaining: 13m 41s\n",
      "3:\tlearn: 6.1454870\ttotal: 3.31s\tremaining: 13m 42s\n",
      "4:\tlearn: 6.0006252\ttotal: 4.02s\tremaining: 13m 20s\n",
      "5:\tlearn: 5.8633380\ttotal: 4.75s\tremaining: 13m 7s\n",
      "6:\tlearn: 5.7296083\ttotal: 5.46s\tremaining: 12m 54s\n",
      "7:\tlearn: 5.6014917\ttotal: 6.16s\tremaining: 12m 44s\n",
      "8:\tlearn: 5.4772532\ttotal: 6.89s\tremaining: 12m 38s\n",
      "9:\tlearn: 5.3605180\ttotal: 7.66s\tremaining: 12m 38s\n",
      "10:\tlearn: 5.2448649\ttotal: 8.46s\tremaining: 12m 41s\n",
      "11:\tlearn: 5.1350263\ttotal: 9.29s\tremaining: 12m 44s\n",
      "12:\tlearn: 5.0284964\ttotal: 10.1s\tremaining: 12m 47s\n",
      "13:\tlearn: 4.9230028\ttotal: 11s\tremaining: 12m 51s\n",
      "14:\tlearn: 4.8248950\ttotal: 11.7s\tremaining: 12m 47s\n",
      "15:\tlearn: 4.7283887\ttotal: 12.4s\tremaining: 12m 42s\n",
      "16:\tlearn: 4.6392323\ttotal: 13.1s\tremaining: 12m 38s\n",
      "17:\tlearn: 4.5489645\ttotal: 13.8s\tremaining: 12m 35s\n",
      "18:\tlearn: 4.4632721\ttotal: 14.6s\tremaining: 12m 31s\n",
      "19:\tlearn: 4.3826229\ttotal: 15.3s\tremaining: 12m 27s\n",
      "20:\tlearn: 4.3025836\ttotal: 16s\tremaining: 12m 25s\n",
      "21:\tlearn: 4.2269931\ttotal: 16.9s\tremaining: 12m 29s\n",
      "22:\tlearn: 4.1542087\ttotal: 17.7s\tremaining: 12m 32s\n",
      "23:\tlearn: 4.0830843\ttotal: 18.5s\tremaining: 12m 33s\n",
      "24:\tlearn: 4.0163505\ttotal: 19.3s\tremaining: 12m 31s\n",
      "25:\tlearn: 3.9522442\ttotal: 20s\tremaining: 12m 29s\n",
      "26:\tlearn: 3.8905163\ttotal: 20.7s\tremaining: 12m 27s\n",
      "27:\tlearn: 3.8302578\ttotal: 21.4s\tremaining: 12m 24s\n",
      "28:\tlearn: 3.7736408\ttotal: 22.1s\tremaining: 12m 21s\n",
      "29:\tlearn: 3.7187440\ttotal: 22.9s\tremaining: 12m 19s\n",
      "30:\tlearn: 3.6665983\ttotal: 23.6s\tremaining: 12m 16s\n",
      "31:\tlearn: 3.6166324\ttotal: 24.4s\tremaining: 12m 17s\n",
      "32:\tlearn: 3.5687873\ttotal: 25.2s\tremaining: 12m 19s\n",
      "33:\tlearn: 3.5238844\ttotal: 26.1s\tremaining: 12m 20s\n",
      "34:\tlearn: 3.4801117\ttotal: 26.8s\tremaining: 12m 20s\n",
      "35:\tlearn: 3.4383061\ttotal: 27.6s\tremaining: 12m 19s\n",
      "36:\tlearn: 3.3988653\ttotal: 28.4s\tremaining: 12m 18s\n",
      "37:\tlearn: 3.3607134\ttotal: 29.2s\tremaining: 12m 19s\n",
      "38:\tlearn: 3.3247325\ttotal: 30s\tremaining: 12m 18s\n",
      "39:\tlearn: 3.2899156\ttotal: 30.7s\tremaining: 12m 17s\n",
      "40:\tlearn: 3.2569098\ttotal: 31.7s\tremaining: 12m 21s\n",
      "41:\tlearn: 3.2255804\ttotal: 32.7s\tremaining: 12m 25s\n",
      "42:\tlearn: 3.1950883\ttotal: 33.6s\tremaining: 12m 28s\n",
      "43:\tlearn: 3.1663671\ttotal: 34.7s\tremaining: 12m 33s\n",
      "44:\tlearn: 3.1387722\ttotal: 35.4s\tremaining: 12m 32s\n",
      "45:\tlearn: 3.1133120\ttotal: 36.3s\tremaining: 12m 32s\n",
      "46:\tlearn: 3.0883767\ttotal: 37.2s\tremaining: 12m 33s\n",
      "47:\tlearn: 3.0647973\ttotal: 38s\tremaining: 12m 32s\n",
      "48:\tlearn: 3.0430721\ttotal: 38.7s\tremaining: 12m 31s\n",
      "49:\tlearn: 3.0217868\ttotal: 39.5s\tremaining: 12m 30s\n",
      "50:\tlearn: 3.0015967\ttotal: 40.5s\tremaining: 12m 32s\n",
      "51:\tlearn: 2.9818020\ttotal: 41.4s\tremaining: 12m 34s\n",
      "52:\tlearn: 2.9637374\ttotal: 42.3s\tremaining: 12m 35s\n",
      "53:\tlearn: 2.9455099\ttotal: 43.1s\tremaining: 12m 34s\n",
      "54:\tlearn: 2.9291831\ttotal: 43.9s\tremaining: 12m 33s\n",
      "55:\tlearn: 2.9134786\ttotal: 44.7s\tremaining: 12m 32s\n",
      "56:\tlearn: 2.8983737\ttotal: 45.5s\tremaining: 12m 31s\n",
      "57:\tlearn: 2.8830006\ttotal: 46.2s\tremaining: 12m 30s\n",
      "58:\tlearn: 2.8686352\ttotal: 47s\tremaining: 12m 29s\n",
      "59:\tlearn: 2.8566569\ttotal: 47.9s\tremaining: 12m 30s\n",
      "60:\tlearn: 2.8441013\ttotal: 48.8s\tremaining: 12m 31s\n",
      "61:\tlearn: 2.8324793\ttotal: 49.7s\tremaining: 12m 32s\n",
      "62:\tlearn: 2.8213027\ttotal: 50.7s\tremaining: 12m 34s\n",
      "63:\tlearn: 2.8108343\ttotal: 51.5s\tremaining: 12m 33s\n",
      "64:\tlearn: 2.8002252\ttotal: 52.3s\tremaining: 12m 31s\n",
      "65:\tlearn: 2.7911798\ttotal: 53.1s\tremaining: 12m 30s\n",
      "66:\tlearn: 2.7819019\ttotal: 53.8s\tremaining: 12m 29s\n",
      "67:\tlearn: 2.7730069\ttotal: 54.6s\tremaining: 12m 28s\n",
      "68:\tlearn: 2.7647106\ttotal: 55.4s\tremaining: 12m 27s\n",
      "69:\tlearn: 2.7571072\ttotal: 56.4s\tremaining: 12m 28s\n",
      "70:\tlearn: 2.7495066\ttotal: 57.3s\tremaining: 12m 29s\n",
      "71:\tlearn: 2.7421209\ttotal: 58.3s\tremaining: 12m 31s\n",
      "72:\tlearn: 2.7350856\ttotal: 59.2s\tremaining: 12m 31s\n",
      "73:\tlearn: 2.7283606\ttotal: 60s\tremaining: 12m 30s\n",
      "74:\tlearn: 2.7221046\ttotal: 1m\tremaining: 12m 29s\n",
      "75:\tlearn: 2.7157343\ttotal: 1m 1s\tremaining: 12m 29s\n",
      "76:\tlearn: 2.7101484\ttotal: 1m 2s\tremaining: 12m 28s\n",
      "77:\tlearn: 2.7046089\ttotal: 1m 3s\tremaining: 12m 27s\n",
      "78:\tlearn: 2.6993047\ttotal: 1m 4s\tremaining: 12m 28s\n",
      "79:\tlearn: 2.6940705\ttotal: 1m 5s\tremaining: 12m 29s\n",
      "80:\tlearn: 2.6897707\ttotal: 1m 6s\tremaining: 12m 30s\n",
      "81:\tlearn: 2.6856747\ttotal: 1m 7s\tremaining: 12m 30s\n",
      "82:\tlearn: 2.6808047\ttotal: 1m 7s\tremaining: 12m 29s\n",
      "83:\tlearn: 2.6768398\ttotal: 1m 8s\tremaining: 12m 29s\n",
      "84:\tlearn: 2.6728757\ttotal: 1m 9s\tremaining: 12m 29s\n",
      "85:\tlearn: 2.6693923\ttotal: 1m 10s\tremaining: 12m 27s\n",
      "86:\tlearn: 2.6649024\ttotal: 1m 11s\tremaining: 12m 26s\n",
      "87:\tlearn: 2.6619040\ttotal: 1m 12s\tremaining: 12m 26s\n",
      "88:\tlearn: 2.6592326\ttotal: 1m 13s\tremaining: 12m 27s\n",
      "89:\tlearn: 2.6561476\ttotal: 1m 13s\tremaining: 12m 27s\n",
      "90:\tlearn: 2.6530160\ttotal: 1m 14s\tremaining: 12m 27s\n",
      "91:\tlearn: 2.6491308\ttotal: 1m 15s\tremaining: 12m 26s\n",
      "92:\tlearn: 2.6462017\ttotal: 1m 16s\tremaining: 12m 25s\n",
      "93:\tlearn: 2.6437882\ttotal: 1m 17s\tremaining: 12m 24s\n",
      "94:\tlearn: 2.6409791\ttotal: 1m 18s\tremaining: 12m 23s\n",
      "95:\tlearn: 2.6389311\ttotal: 1m 18s\tremaining: 12m 22s\n",
      "96:\tlearn: 2.6367761\ttotal: 1m 19s\tremaining: 12m 20s\n",
      "97:\tlearn: 2.6339255\ttotal: 1m 20s\tremaining: 12m 20s\n",
      "98:\tlearn: 2.6316464\ttotal: 1m 21s\tremaining: 12m 20s\n",
      "99:\tlearn: 2.6296727\ttotal: 1m 22s\tremaining: 12m 20s\n",
      "100:\tlearn: 2.6278479\ttotal: 1m 23s\tremaining: 12m 20s\n",
      "101:\tlearn: 2.6264056\ttotal: 1m 23s\tremaining: 12m 19s\n",
      "102:\tlearn: 2.6243798\ttotal: 1m 24s\tremaining: 12m 18s\n",
      "103:\tlearn: 2.6220900\ttotal: 1m 25s\tremaining: 12m 18s\n",
      "104:\tlearn: 2.6192024\ttotal: 1m 26s\tremaining: 12m 17s\n",
      "105:\tlearn: 2.6172579\ttotal: 1m 27s\tremaining: 12m 16s\n",
      "106:\tlearn: 2.6158067\ttotal: 1m 28s\tremaining: 12m 15s\n",
      "107:\tlearn: 2.6140980\ttotal: 1m 29s\tremaining: 12m 16s\n",
      "108:\tlearn: 2.6118790\ttotal: 1m 30s\tremaining: 12m 16s\n",
      "109:\tlearn: 2.6105781\ttotal: 1m 31s\tremaining: 12m 16s\n",
      "110:\tlearn: 2.6094694\ttotal: 1m 31s\tremaining: 12m 16s\n",
      "111:\tlearn: 2.6078690\ttotal: 1m 32s\tremaining: 12m 15s\n",
      "112:\tlearn: 2.6064426\ttotal: 1m 33s\tremaining: 12m 13s\n",
      "113:\tlearn: 2.6052888\ttotal: 1m 34s\tremaining: 12m 12s\n",
      "114:\tlearn: 2.6042471\ttotal: 1m 35s\tremaining: 12m 11s\n",
      "115:\tlearn: 2.6031542\ttotal: 1m 35s\tremaining: 12m 10s\n",
      "116:\tlearn: 2.6014816\ttotal: 1m 36s\tremaining: 12m 9s\n",
      "117:\tlearn: 2.6002971\ttotal: 1m 37s\tremaining: 12m 10s\n",
      "118:\tlearn: 2.5984288\ttotal: 1m 38s\tremaining: 12m 10s\n",
      "119:\tlearn: 2.5970201\ttotal: 1m 39s\tremaining: 12m 10s\n",
      "120:\tlearn: 2.5960166\ttotal: 1m 40s\tremaining: 12m 8s\n",
      "121:\tlearn: 2.5948882\ttotal: 1m 41s\tremaining: 12m 8s\n",
      "122:\tlearn: 2.5932765\ttotal: 1m 41s\tremaining: 12m 7s\n",
      "123:\tlearn: 2.5922119\ttotal: 1m 42s\tremaining: 12m 5s\n",
      "124:\tlearn: 2.5917119\ttotal: 1m 42s\tremaining: 12m\n",
      "125:\tlearn: 2.5906428\ttotal: 1m 43s\tremaining: 11m 59s\n",
      "126:\tlearn: 2.5892715\ttotal: 1m 44s\tremaining: 11m 58s\n",
      "127:\tlearn: 2.5878929\ttotal: 1m 45s\tremaining: 11m 58s\n",
      "128:\tlearn: 2.5867833\ttotal: 1m 46s\tremaining: 11m 58s\n",
      "129:\tlearn: 2.5860598\ttotal: 1m 47s\tremaining: 11m 58s\n",
      "130:\tlearn: 2.5848780\ttotal: 1m 48s\tremaining: 11m 57s\n",
      "131:\tlearn: 2.5840342\ttotal: 1m 48s\tremaining: 11m 56s\n",
      "132:\tlearn: 2.5828353\ttotal: 1m 49s\tremaining: 11m 55s\n",
      "133:\tlearn: 2.5818267\ttotal: 1m 50s\tremaining: 11m 54s\n",
      "134:\tlearn: 2.5805368\ttotal: 1m 51s\tremaining: 11m 52s\n",
      "135:\tlearn: 2.5788251\ttotal: 1m 52s\tremaining: 11m 51s\n",
      "136:\tlearn: 2.5777822\ttotal: 1m 52s\tremaining: 11m 51s\n",
      "137:\tlearn: 2.5766770\ttotal: 1m 53s\tremaining: 11m 51s\n",
      "138:\tlearn: 2.5760268\ttotal: 1m 54s\tremaining: 11m 51s\n",
      "139:\tlearn: 2.5753668\ttotal: 1m 55s\tremaining: 11m 50s\n",
      "140:\tlearn: 2.5747071\ttotal: 1m 56s\tremaining: 11m 49s\n",
      "141:\tlearn: 2.5740737\ttotal: 1m 57s\tremaining: 11m 48s\n",
      "142:\tlearn: 2.5732745\ttotal: 1m 58s\tremaining: 11m 47s\n",
      "143:\tlearn: 2.5720948\ttotal: 1m 58s\tremaining: 11m 46s\n",
      "144:\tlearn: 2.5710627\ttotal: 1m 59s\tremaining: 11m 45s\n",
      "145:\tlearn: 2.5700107\ttotal: 2m\tremaining: 11m 44s\n",
      "146:\tlearn: 2.5678184\ttotal: 2m 1s\tremaining: 11m 44s\n",
      "147:\tlearn: 2.5673365\ttotal: 2m 2s\tremaining: 11m 44s\n",
      "148:\tlearn: 2.5663653\ttotal: 2m 3s\tremaining: 11m 43s\n",
      "149:\tlearn: 2.5659704\ttotal: 2m 4s\tremaining: 11m 43s\n",
      "150:\tlearn: 2.5656953\ttotal: 2m 4s\tremaining: 11m 42s\n",
      "151:\tlearn: 2.5648434\ttotal: 2m 5s\tremaining: 11m 41s\n",
      "152:\tlearn: 2.5641219\ttotal: 2m 6s\tremaining: 11m 40s\n",
      "153:\tlearn: 2.5630682\ttotal: 2m 7s\tremaining: 11m 39s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154:\tlearn: 2.5619992\ttotal: 2m 8s\tremaining: 11m 38s\n",
      "155:\tlearn: 2.5611108\ttotal: 2m 8s\tremaining: 11m 37s\n",
      "156:\tlearn: 2.5601984\ttotal: 2m 9s\tremaining: 11m 37s\n",
      "157:\tlearn: 2.5584587\ttotal: 2m 10s\tremaining: 11m 37s\n",
      "158:\tlearn: 2.5580340\ttotal: 2m 11s\tremaining: 11m 36s\n",
      "159:\tlearn: 2.5575522\ttotal: 2m 12s\tremaining: 11m 35s\n",
      "160:\tlearn: 2.5570300\ttotal: 2m 13s\tremaining: 11m 34s\n",
      "161:\tlearn: 2.5560971\ttotal: 2m 14s\tremaining: 11m 33s\n",
      "162:\tlearn: 2.5552507\ttotal: 2m 14s\tremaining: 11m 32s\n",
      "163:\tlearn: 2.5548037\ttotal: 2m 15s\tremaining: 11m 31s\n",
      "164:\tlearn: 2.5543791\ttotal: 2m 16s\tremaining: 11m 30s\n",
      "165:\tlearn: 2.5540469\ttotal: 2m 17s\tremaining: 11m 29s\n",
      "166:\tlearn: 2.5530823\ttotal: 2m 18s\tremaining: 11m 29s\n",
      "167:\tlearn: 2.5528282\ttotal: 2m 19s\tremaining: 11m 29s\n",
      "168:\tlearn: 2.5524656\ttotal: 2m 20s\tremaining: 11m 28s\n",
      "169:\tlearn: 2.5514280\ttotal: 2m 20s\tremaining: 11m 27s\n",
      "170:\tlearn: 2.5509021\ttotal: 2m 21s\tremaining: 11m 26s\n",
      "171:\tlearn: 2.5500749\ttotal: 2m 22s\tremaining: 11m 25s\n",
      "172:\tlearn: 2.5494358\ttotal: 2m 23s\tremaining: 11m 24s\n",
      "173:\tlearn: 2.5491724\ttotal: 2m 24s\tremaining: 11m 23s\n",
      "174:\tlearn: 2.5486520\ttotal: 2m 24s\tremaining: 11m 22s\n",
      "175:\tlearn: 2.5480765\ttotal: 2m 25s\tremaining: 11m 22s\n",
      "176:\tlearn: 2.5476768\ttotal: 2m 26s\tremaining: 11m 22s\n",
      "177:\tlearn: 2.5470002\ttotal: 2m 27s\tremaining: 11m 22s\n",
      "178:\tlearn: 2.5467654\ttotal: 2m 28s\tremaining: 11m 20s\n",
      "179:\tlearn: 2.5458927\ttotal: 2m 29s\tremaining: 11m 20s\n",
      "180:\tlearn: 2.5456125\ttotal: 2m 30s\tremaining: 11m 19s\n",
      "181:\tlearn: 2.5451655\ttotal: 2m 30s\tremaining: 11m 18s\n",
      "182:\tlearn: 2.5446067\ttotal: 2m 31s\tremaining: 11m 17s\n",
      "183:\tlearn: 2.5444964\ttotal: 2m 32s\tremaining: 11m 16s\n",
      "184:\tlearn: 2.5439447\ttotal: 2m 33s\tremaining: 11m 15s\n",
      "185:\tlearn: 2.5436556\ttotal: 2m 34s\tremaining: 11m 15s\n",
      "186:\tlearn: 2.5427406\ttotal: 2m 35s\tremaining: 11m 14s\n",
      "187:\tlearn: 2.5416493\ttotal: 2m 36s\tremaining: 11m 14s\n",
      "188:\tlearn: 2.5408744\ttotal: 2m 36s\tremaining: 11m 13s\n",
      "189:\tlearn: 2.5400344\ttotal: 2m 37s\tremaining: 11m 12s\n",
      "190:\tlearn: 2.5386128\ttotal: 2m 38s\tremaining: 11m 11s\n",
      "191:\tlearn: 2.5380215\ttotal: 2m 39s\tremaining: 11m 10s\n",
      "192:\tlearn: 2.5376626\ttotal: 2m 40s\tremaining: 11m 9s\n",
      "193:\tlearn: 2.5374634\ttotal: 2m 40s\tremaining: 11m 8s\n",
      "194:\tlearn: 2.5372232\ttotal: 2m 41s\tremaining: 11m 8s\n",
      "195:\tlearn: 2.5361962\ttotal: 2m 42s\tremaining: 11m 7s\n",
      "196:\tlearn: 2.5357121\ttotal: 2m 43s\tremaining: 11m 7s\n",
      "197:\tlearn: 2.5347998\ttotal: 2m 44s\tremaining: 11m 6s\n",
      "198:\tlearn: 2.5343457\ttotal: 2m 45s\tremaining: 11m 5s\n",
      "199:\tlearn: 2.5340702\ttotal: 2m 46s\tremaining: 11m 4s\n",
      "200:\tlearn: 2.5340271\ttotal: 2m 46s\tremaining: 11m\n",
      "201:\tlearn: 2.5337087\ttotal: 2m 47s\tremaining: 10m 59s\n",
      "202:\tlearn: 2.5333679\ttotal: 2m 47s\tremaining: 10m 58s\n",
      "203:\tlearn: 2.5328160\ttotal: 2m 48s\tremaining: 10m 59s\n",
      "204:\tlearn: 2.5320273\ttotal: 2m 49s\tremaining: 10m 58s\n",
      "205:\tlearn: 2.5314942\ttotal: 2m 50s\tremaining: 10m 58s\n",
      "206:\tlearn: 2.5309606\ttotal: 2m 51s\tremaining: 10m 57s\n",
      "207:\tlearn: 2.5302494\ttotal: 2m 52s\tremaining: 10m 56s\n",
      "208:\tlearn: 2.5291918\ttotal: 2m 53s\tremaining: 10m 55s\n",
      "209:\tlearn: 2.5289545\ttotal: 2m 54s\tremaining: 10m 54s\n",
      "210:\tlearn: 2.5282742\ttotal: 2m 54s\tremaining: 10m 53s\n",
      "211:\tlearn: 2.5282099\ttotal: 2m 55s\tremaining: 10m 52s\n",
      "212:\tlearn: 2.5277710\ttotal: 2m 56s\tremaining: 10m 51s\n",
      "213:\tlearn: 2.5274532\ttotal: 2m 57s\tremaining: 10m 51s\n",
      "214:\tlearn: 2.5269562\ttotal: 2m 58s\tremaining: 10m 50s\n",
      "215:\tlearn: 2.5261710\ttotal: 2m 59s\tremaining: 10m 50s\n",
      "216:\tlearn: 2.5261087\ttotal: 3m\tremaining: 10m 49s\n",
      "217:\tlearn: 2.5260124\ttotal: 3m\tremaining: 10m 48s\n",
      "218:\tlearn: 2.5257051\ttotal: 3m 1s\tremaining: 10m 47s\n",
      "219:\tlearn: 2.5252570\ttotal: 3m 2s\tremaining: 10m 47s\n",
      "220:\tlearn: 2.5251409\ttotal: 3m 3s\tremaining: 10m 46s\n",
      "221:\tlearn: 2.5241084\ttotal: 3m 4s\tremaining: 10m 45s\n",
      "222:\tlearn: 2.5233084\ttotal: 3m 4s\tremaining: 10m 44s\n",
      "223:\tlearn: 2.5226077\ttotal: 3m 5s\tremaining: 10m 43s\n",
      "224:\tlearn: 2.5222520\ttotal: 3m 6s\tremaining: 10m 43s\n",
      "225:\tlearn: 2.5212439\ttotal: 3m 7s\tremaining: 10m 42s\n",
      "226:\tlearn: 2.5209188\ttotal: 3m 8s\tremaining: 10m 42s\n",
      "227:\tlearn: 2.5201732\ttotal: 3m 9s\tremaining: 10m 41s\n",
      "228:\tlearn: 2.5199006\ttotal: 3m 10s\tremaining: 10m 40s\n",
      "229:\tlearn: 2.5191296\ttotal: 3m 10s\tremaining: 10m 39s\n",
      "230:\tlearn: 2.5168628\ttotal: 3m 11s\tremaining: 10m 38s\n",
      "231:\tlearn: 2.5164890\ttotal: 3m 12s\tremaining: 10m 37s\n",
      "232:\tlearn: 2.5163255\ttotal: 3m 13s\tremaining: 10m 36s\n",
      "233:\tlearn: 2.5158649\ttotal: 3m 14s\tremaining: 10m 36s\n",
      "234:\tlearn: 2.5156101\ttotal: 3m 15s\tremaining: 10m 35s\n",
      "235:\tlearn: 2.5142199\ttotal: 3m 16s\tremaining: 10m 35s\n",
      "236:\tlearn: 2.5136215\ttotal: 3m 17s\tremaining: 10m 34s\n",
      "237:\tlearn: 2.5135970\ttotal: 3m 17s\tremaining: 10m 33s\n",
      "238:\tlearn: 2.5128420\ttotal: 3m 18s\tremaining: 10m 32s\n",
      "239:\tlearn: 2.5118116\ttotal: 3m 19s\tremaining: 10m 31s\n",
      "240:\tlearn: 2.5116478\ttotal: 3m 20s\tremaining: 10m 30s\n",
      "241:\tlearn: 2.5110692\ttotal: 3m 20s\tremaining: 10m 29s\n",
      "242:\tlearn: 2.5106856\ttotal: 3m 21s\tremaining: 10m 28s\n",
      "243:\tlearn: 2.5095594\ttotal: 3m 22s\tremaining: 10m 28s\n",
      "244:\tlearn: 2.5092999\ttotal: 3m 23s\tremaining: 10m 28s\n",
      "245:\tlearn: 2.5088877\ttotal: 3m 24s\tremaining: 10m 27s\n",
      "246:\tlearn: 2.5084984\ttotal: 3m 25s\tremaining: 10m 26s\n",
      "247:\tlearn: 2.5082052\ttotal: 3m 26s\tremaining: 10m 25s\n",
      "248:\tlearn: 2.5076171\ttotal: 3m 26s\tremaining: 10m 24s\n",
      "249:\tlearn: 2.5069436\ttotal: 3m 27s\tremaining: 10m 23s\n",
      "250:\tlearn: 2.5062135\ttotal: 3m 28s\tremaining: 10m 22s\n",
      "251:\tlearn: 2.5055781\ttotal: 3m 29s\tremaining: 10m 22s\n",
      "252:\tlearn: 2.5046567\ttotal: 3m 30s\tremaining: 10m 21s\n",
      "253:\tlearn: 2.5037529\ttotal: 3m 31s\tremaining: 10m 21s\n",
      "254:\tlearn: 2.5031909\ttotal: 3m 32s\tremaining: 10m 20s\n",
      "255:\tlearn: 2.5028214\ttotal: 3m 33s\tremaining: 10m 19s\n",
      "256:\tlearn: 2.5028003\ttotal: 3m 33s\tremaining: 10m 16s\n",
      "257:\tlearn: 2.5026751\ttotal: 3m 34s\tremaining: 10m 15s\n",
      "258:\tlearn: 2.5022603\ttotal: 3m 34s\tremaining: 10m 14s\n",
      "259:\tlearn: 2.5013275\ttotal: 3m 35s\tremaining: 10m 13s\n",
      "260:\tlearn: 2.5013274\ttotal: 3m 35s\tremaining: 10m 10s\n",
      "261:\tlearn: 2.5013270\ttotal: 3m 35s\tremaining: 10m 8s\n",
      "262:\tlearn: 2.5010512\ttotal: 3m 36s\tremaining: 10m 7s\n",
      "263:\tlearn: 2.4999892\ttotal: 3m 37s\tremaining: 10m 6s\n",
      "264:\tlearn: 2.4985760\ttotal: 3m 38s\tremaining: 10m 6s\n",
      "265:\tlearn: 2.4982444\ttotal: 3m 39s\tremaining: 10m 5s\n",
      "266:\tlearn: 2.4981874\ttotal: 3m 40s\tremaining: 10m 5s\n",
      "267:\tlearn: 2.4980960\ttotal: 3m 41s\tremaining: 10m 4s\n",
      "268:\tlearn: 2.4978242\ttotal: 3m 42s\tremaining: 10m 3s\n",
      "269:\tlearn: 2.4978024\ttotal: 3m 42s\tremaining: 10m 1s\n",
      "270:\tlearn: 2.4974436\ttotal: 3m 43s\tremaining: 10m\n",
      "271:\tlearn: 2.4961899\ttotal: 3m 44s\tremaining: 9m 59s\n",
      "272:\tlearn: 2.4944160\ttotal: 3m 44s\tremaining: 9m 58s\n",
      "273:\tlearn: 2.4935469\ttotal: 3m 45s\tremaining: 9m 58s\n",
      "274:\tlearn: 2.4930224\ttotal: 3m 46s\tremaining: 9m 58s\n",
      "275:\tlearn: 2.4922864\ttotal: 3m 47s\tremaining: 9m 57s\n",
      "276:\tlearn: 2.4914235\ttotal: 3m 49s\tremaining: 9m 57s\n",
      "277:\tlearn: 2.4906600\ttotal: 3m 49s\tremaining: 9m 56s\n",
      "278:\tlearn: 2.4906407\ttotal: 3m 50s\tremaining: 9m 56s\n",
      "279:\tlearn: 2.4895437\ttotal: 3m 51s\tremaining: 9m 55s\n",
      "280:\tlearn: 2.4895021\ttotal: 3m 52s\tremaining: 9m 54s\n",
      "281:\tlearn: 2.4894910\ttotal: 3m 52s\tremaining: 9m 53s\n",
      "282:\tlearn: 2.4892151\ttotal: 3m 53s\tremaining: 9m 51s\n",
      "283:\tlearn: 2.4878436\ttotal: 3m 54s\tremaining: 9m 50s\n",
      "284:\tlearn: 2.4873138\ttotal: 3m 55s\tremaining: 9m 49s\n",
      "285:\tlearn: 2.4866975\ttotal: 3m 56s\tremaining: 9m 49s\n",
      "286:\tlearn: 2.4865988\ttotal: 3m 56s\tremaining: 9m 48s\n",
      "287:\tlearn: 2.4856964\ttotal: 3m 57s\tremaining: 9m 47s\n",
      "288:\tlearn: 2.4855513\ttotal: 3m 58s\tremaining: 9m 46s\n",
      "289:\tlearn: 2.4855336\ttotal: 3m 58s\tremaining: 9m 44s\n",
      "290:\tlearn: 2.4847202\ttotal: 3m 59s\tremaining: 9m 43s\n",
      "291:\tlearn: 2.4834250\ttotal: 4m\tremaining: 9m 42s\n",
      "292:\tlearn: 2.4817054\ttotal: 4m\tremaining: 9m 41s\n",
      "293:\tlearn: 2.4816864\ttotal: 4m 1s\tremaining: 9m 39s\n",
      "294:\tlearn: 2.4816238\ttotal: 4m 2s\tremaining: 9m 38s\n",
      "295:\tlearn: 2.4803957\ttotal: 4m 2s\tremaining: 9m 37s\n",
      "296:\tlearn: 2.4796664\ttotal: 4m 3s\tremaining: 9m 37s\n",
      "297:\tlearn: 2.4796571\ttotal: 4m 4s\tremaining: 9m 36s\n",
      "298:\tlearn: 2.4792472\ttotal: 4m 5s\tremaining: 9m 35s\n",
      "299:\tlearn: 2.4792472\ttotal: 4m 5s\tremaining: 9m 33s\n",
      "300:\tlearn: 2.4792291\ttotal: 4m 6s\tremaining: 9m 31s\n",
      "301:\tlearn: 2.4778765\ttotal: 4m 6s\tremaining: 9m 30s\n",
      "302:\tlearn: 2.4774035\ttotal: 4m 7s\tremaining: 9m 30s\n",
      "303:\tlearn: 2.4773870\ttotal: 4m 7s\tremaining: 9m 27s\n",
      "304:\tlearn: 2.4768356\ttotal: 4m 8s\tremaining: 9m 26s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305:\tlearn: 2.4760063\ttotal: 4m 9s\tremaining: 9m 25s\n",
      "306:\tlearn: 2.4755057\ttotal: 4m 10s\tremaining: 9m 25s\n",
      "307:\tlearn: 2.4754780\ttotal: 4m 11s\tremaining: 9m 25s\n",
      "308:\tlearn: 2.4752528\ttotal: 4m 12s\tremaining: 9m 24s\n",
      "309:\tlearn: 2.4750756\ttotal: 4m 13s\tremaining: 9m 24s\n",
      "310:\tlearn: 2.4738501\ttotal: 4m 14s\tremaining: 9m 23s\n",
      "311:\tlearn: 2.4733637\ttotal: 4m 15s\tremaining: 9m 22s\n",
      "312:\tlearn: 2.4723373\ttotal: 4m 15s\tremaining: 9m 21s\n",
      "313:\tlearn: 2.4706638\ttotal: 4m 16s\tremaining: 9m 21s\n",
      "314:\tlearn: 2.4694692\ttotal: 4m 17s\tremaining: 9m 20s\n",
      "315:\tlearn: 2.4693325\ttotal: 4m 18s\tremaining: 9m 19s\n",
      "316:\tlearn: 2.4692295\ttotal: 4m 19s\tremaining: 9m 19s\n",
      "317:\tlearn: 2.4688105\ttotal: 4m 20s\tremaining: 9m 18s\n",
      "318:\tlearn: 2.4683802\ttotal: 4m 21s\tremaining: 9m 18s\n",
      "319:\tlearn: 2.4680565\ttotal: 4m 22s\tremaining: 9m 17s\n",
      "320:\tlearn: 2.4672633\ttotal: 4m 23s\tremaining: 9m 16s\n",
      "321:\tlearn: 2.4664148\ttotal: 4m 23s\tremaining: 9m 15s\n",
      "322:\tlearn: 2.4661271\ttotal: 4m 24s\tremaining: 9m 15s\n",
      "323:\tlearn: 2.4655138\ttotal: 4m 26s\tremaining: 9m 15s\n",
      "324:\tlearn: 2.4654773\ttotal: 4m 27s\tremaining: 9m 15s\n",
      "325:\tlearn: 2.4654620\ttotal: 4m 27s\tremaining: 9m 13s\n",
      "326:\tlearn: 2.4639078\ttotal: 4m 29s\tremaining: 9m 14s\n",
      "327:\tlearn: 2.4635428\ttotal: 4m 30s\tremaining: 9m 13s\n",
      "328:\tlearn: 2.4626295\ttotal: 4m 31s\tremaining: 9m 12s\n",
      "329:\tlearn: 2.4622419\ttotal: 4m 31s\tremaining: 9m 12s\n",
      "330:\tlearn: 2.4608654\ttotal: 4m 32s\tremaining: 9m 11s\n",
      "331:\tlearn: 2.4593209\ttotal: 4m 33s\tremaining: 9m 10s\n",
      "332:\tlearn: 2.4579343\ttotal: 4m 34s\tremaining: 9m 9s\n",
      "333:\tlearn: 2.4568163\ttotal: 4m 35s\tremaining: 9m 8s\n",
      "334:\tlearn: 2.4560087\ttotal: 4m 36s\tremaining: 9m 8s\n",
      "335:\tlearn: 2.4555016\ttotal: 4m 37s\tremaining: 9m 7s\n",
      "336:\tlearn: 2.4542061\ttotal: 4m 38s\tremaining: 9m 7s\n",
      "337:\tlearn: 2.4536140\ttotal: 4m 38s\tremaining: 9m 6s\n",
      "338:\tlearn: 2.4522746\ttotal: 4m 39s\tremaining: 9m 5s\n",
      "339:\tlearn: 2.4504663\ttotal: 4m 40s\tremaining: 9m 4s\n",
      "340:\tlearn: 2.4500526\ttotal: 4m 41s\tremaining: 9m 3s\n",
      "341:\tlearn: 2.4493939\ttotal: 4m 42s\tremaining: 9m 2s\n",
      "342:\tlearn: 2.4491946\ttotal: 4m 42s\tremaining: 9m 1s\n",
      "343:\tlearn: 2.4491784\ttotal: 4m 43s\tremaining: 9m\n",
      "344:\tlearn: 2.4477893\ttotal: 4m 44s\tremaining: 9m\n",
      "345:\tlearn: 2.4474573\ttotal: 4m 45s\tremaining: 8m 59s\n",
      "346:\tlearn: 2.4466316\ttotal: 4m 46s\tremaining: 8m 59s\n",
      "347:\tlearn: 2.4457476\ttotal: 4m 47s\tremaining: 8m 58s\n",
      "348:\tlearn: 2.4439578\ttotal: 4m 48s\tremaining: 8m 57s\n",
      "349:\tlearn: 2.4428535\ttotal: 4m 49s\tremaining: 8m 56s\n",
      "350:\tlearn: 2.4419915\ttotal: 4m 49s\tremaining: 8m 56s\n",
      "351:\tlearn: 2.4409806\ttotal: 4m 50s\tremaining: 8m 55s\n",
      "352:\tlearn: 2.4401548\ttotal: 4m 51s\tremaining: 8m 54s\n",
      "353:\tlearn: 2.4396118\ttotal: 4m 52s\tremaining: 8m 53s\n",
      "354:\tlearn: 2.4389445\ttotal: 4m 53s\tremaining: 8m 53s\n",
      "355:\tlearn: 2.4384312\ttotal: 4m 54s\tremaining: 8m 52s\n",
      "356:\tlearn: 2.4382091\ttotal: 4m 55s\tremaining: 8m 51s\n",
      "357:\tlearn: 2.4373788\ttotal: 4m 56s\tremaining: 8m 50s\n",
      "358:\tlearn: 2.4363004\ttotal: 4m 56s\tremaining: 8m 50s\n",
      "359:\tlearn: 2.4354162\ttotal: 4m 57s\tremaining: 8m 49s\n",
      "360:\tlearn: 2.4352570\ttotal: 4m 58s\tremaining: 8m 48s\n",
      "361:\tlearn: 2.4352486\ttotal: 4m 58s\tremaining: 8m 46s\n",
      "362:\tlearn: 2.4345274\ttotal: 4m 59s\tremaining: 8m 45s\n",
      "363:\tlearn: 2.4344364\ttotal: 5m\tremaining: 8m 45s\n",
      "364:\tlearn: 2.4334416\ttotal: 5m 1s\tremaining: 8m 44s\n",
      "365:\tlearn: 2.4326644\ttotal: 5m 2s\tremaining: 8m 44s\n",
      "366:\tlearn: 2.4326505\ttotal: 5m 2s\tremaining: 8m 42s\n",
      "367:\tlearn: 2.4317899\ttotal: 5m 3s\tremaining: 8m 41s\n",
      "368:\tlearn: 2.4310194\ttotal: 5m 4s\tremaining: 8m 40s\n",
      "369:\tlearn: 2.4310188\ttotal: 5m 4s\tremaining: 8m 38s\n",
      "370:\tlearn: 2.4291524\ttotal: 5m 5s\tremaining: 8m 37s\n",
      "371:\tlearn: 2.4286298\ttotal: 5m 6s\tremaining: 8m 36s\n",
      "372:\tlearn: 2.4276413\ttotal: 5m 6s\tremaining: 8m 36s\n",
      "373:\tlearn: 2.4270478\ttotal: 5m 7s\tremaining: 8m 35s\n",
      "374:\tlearn: 2.4270467\ttotal: 5m 8s\tremaining: 8m 33s\n",
      "375:\tlearn: 2.4270452\ttotal: 5m 8s\tremaining: 8m 32s\n",
      "376:\tlearn: 2.4264994\ttotal: 5m 9s\tremaining: 8m 31s\n",
      "377:\tlearn: 2.4258152\ttotal: 5m 10s\tremaining: 8m 30s\n",
      "378:\tlearn: 2.4253853\ttotal: 5m 11s\tremaining: 8m 30s\n",
      "379:\tlearn: 2.4243414\ttotal: 5m 12s\tremaining: 8m 29s\n",
      "380:\tlearn: 2.4227430\ttotal: 5m 12s\tremaining: 8m 28s\n",
      "381:\tlearn: 2.4214712\ttotal: 5m 13s\tremaining: 8m 27s\n",
      "382:\tlearn: 2.4207551\ttotal: 5m 14s\tremaining: 8m 26s\n",
      "383:\tlearn: 2.4201272\ttotal: 5m 15s\tremaining: 8m 25s\n",
      "384:\tlearn: 2.4193890\ttotal: 5m 16s\tremaining: 8m 24s\n",
      "385:\tlearn: 2.4189710\ttotal: 5m 17s\tremaining: 8m 24s\n",
      "386:\tlearn: 2.4178102\ttotal: 5m 17s\tremaining: 8m 23s\n",
      "387:\tlearn: 2.4164838\ttotal: 5m 18s\tremaining: 8m 22s\n",
      "388:\tlearn: 2.4163673\ttotal: 5m 19s\tremaining: 8m 21s\n",
      "389:\tlearn: 2.4160424\ttotal: 5m 20s\tremaining: 8m 20s\n",
      "390:\tlearn: 2.4144367\ttotal: 5m 21s\tremaining: 8m 20s\n",
      "391:\tlearn: 2.4129829\ttotal: 5m 21s\tremaining: 8m 19s\n",
      "392:\tlearn: 2.4116184\ttotal: 5m 22s\tremaining: 8m 18s\n",
      "393:\tlearn: 2.4109712\ttotal: 5m 23s\tremaining: 8m 17s\n",
      "394:\tlearn: 2.4098221\ttotal: 5m 24s\tremaining: 8m 16s\n",
      "395:\tlearn: 2.4081573\ttotal: 5m 25s\tremaining: 8m 16s\n",
      "396:\tlearn: 2.4068061\ttotal: 5m 26s\tremaining: 8m 15s\n",
      "397:\tlearn: 2.4060235\ttotal: 5m 27s\tremaining: 8m 15s\n",
      "398:\tlearn: 2.4056298\ttotal: 5m 28s\tremaining: 8m 14s\n",
      "399:\tlearn: 2.4045393\ttotal: 5m 29s\tremaining: 8m 13s\n",
      "400:\tlearn: 2.4041688\ttotal: 5m 29s\tremaining: 8m 12s\n",
      "401:\tlearn: 2.4040785\ttotal: 5m 30s\tremaining: 8m 12s\n",
      "402:\tlearn: 2.4039406\ttotal: 5m 31s\tremaining: 8m 11s\n",
      "403:\tlearn: 2.4028544\ttotal: 5m 32s\tremaining: 8m 10s\n",
      "404:\tlearn: 2.4016491\ttotal: 5m 33s\tremaining: 8m 10s\n",
      "405:\tlearn: 2.4009636\ttotal: 5m 34s\tremaining: 8m 9s\n",
      "406:\tlearn: 2.4004544\ttotal: 5m 35s\tremaining: 8m 8s\n",
      "407:\tlearn: 2.4001903\ttotal: 5m 36s\tremaining: 8m 7s\n",
      "408:\tlearn: 2.3990623\ttotal: 5m 36s\tremaining: 8m 6s\n",
      "409:\tlearn: 2.3978318\ttotal: 5m 37s\tremaining: 8m 5s\n",
      "410:\tlearn: 2.3960976\ttotal: 5m 38s\tremaining: 8m 5s\n",
      "411:\tlearn: 2.3949470\ttotal: 5m 39s\tremaining: 8m 4s\n",
      "412:\tlearn: 2.3942988\ttotal: 5m 40s\tremaining: 8m 3s\n",
      "413:\tlearn: 2.3920554\ttotal: 5m 41s\tremaining: 8m 3s\n",
      "414:\tlearn: 2.3914482\ttotal: 5m 42s\tremaining: 8m 2s\n",
      "415:\tlearn: 2.3902688\ttotal: 5m 42s\tremaining: 8m 1s\n",
      "416:\tlearn: 2.3898091\ttotal: 5m 43s\tremaining: 8m\n",
      "417:\tlearn: 2.3885989\ttotal: 5m 44s\tremaining: 7m 59s\n",
      "418:\tlearn: 2.3876421\ttotal: 5m 45s\tremaining: 7m 58s\n",
      "419:\tlearn: 2.3865699\ttotal: 5m 46s\tremaining: 7m 57s\n",
      "420:\tlearn: 2.3852671\ttotal: 5m 46s\tremaining: 7m 57s\n",
      "421:\tlearn: 2.3849420\ttotal: 5m 47s\tremaining: 7m 56s\n",
      "422:\tlearn: 2.3839005\ttotal: 5m 49s\tremaining: 7m 56s\n",
      "423:\tlearn: 2.3838989\ttotal: 5m 49s\tremaining: 7m 55s\n",
      "424:\tlearn: 2.3837921\ttotal: 5m 51s\tremaining: 7m 55s\n",
      "425:\tlearn: 2.3832126\ttotal: 5m 52s\tremaining: 7m 54s\n",
      "426:\tlearn: 2.3830065\ttotal: 5m 53s\tremaining: 7m 53s\n",
      "427:\tlearn: 2.3819024\ttotal: 5m 53s\tremaining: 7m 53s\n",
      "428:\tlearn: 2.3810327\ttotal: 5m 54s\tremaining: 7m 52s\n",
      "429:\tlearn: 2.3806484\ttotal: 5m 55s\tremaining: 7m 51s\n",
      "430:\tlearn: 2.3802841\ttotal: 5m 56s\tremaining: 7m 50s\n",
      "431:\tlearn: 2.3797624\ttotal: 5m 57s\tremaining: 7m 49s\n",
      "432:\tlearn: 2.3792308\ttotal: 5m 58s\tremaining: 7m 49s\n",
      "433:\tlearn: 2.3792166\ttotal: 5m 59s\tremaining: 7m 48s\n",
      "434:\tlearn: 2.3780725\ttotal: 6m\tremaining: 7m 48s\n",
      "435:\tlearn: 2.3773438\ttotal: 6m 1s\tremaining: 7m 47s\n",
      "436:\tlearn: 2.3768183\ttotal: 6m 1s\tremaining: 7m 46s\n",
      "437:\tlearn: 2.3767772\ttotal: 6m 2s\tremaining: 7m 45s\n",
      "438:\tlearn: 2.3760493\ttotal: 6m 3s\tremaining: 7m 44s\n",
      "439:\tlearn: 2.3751202\ttotal: 6m 4s\tremaining: 7m 43s\n",
      "440:\tlearn: 2.3737752\ttotal: 6m 5s\tremaining: 7m 42s\n",
      "441:\tlearn: 2.3737732\ttotal: 6m 5s\tremaining: 7m 41s\n",
      "442:\tlearn: 2.3728357\ttotal: 6m 6s\tremaining: 7m 40s\n",
      "443:\tlearn: 2.3724935\ttotal: 6m 7s\tremaining: 7m 40s\n",
      "444:\tlearn: 2.3724658\ttotal: 6m 8s\tremaining: 7m 39s\n",
      "445:\tlearn: 2.3724633\ttotal: 6m 8s\tremaining: 7m 37s\n",
      "446:\tlearn: 2.3710076\ttotal: 6m 9s\tremaining: 7m 37s\n",
      "447:\tlearn: 2.3707013\ttotal: 6m 10s\tremaining: 7m 36s\n",
      "448:\tlearn: 2.3703276\ttotal: 6m 11s\tremaining: 7m 35s\n",
      "449:\tlearn: 2.3702277\ttotal: 6m 11s\tremaining: 7m 34s\n",
      "450:\tlearn: 2.3689580\ttotal: 6m 12s\tremaining: 7m 33s\n",
      "451:\tlearn: 2.3684024\ttotal: 6m 13s\tremaining: 7m 32s\n",
      "452:\tlearn: 2.3670348\ttotal: 6m 14s\tremaining: 7m 32s\n",
      "453:\tlearn: 2.3667503\ttotal: 6m 15s\tremaining: 7m 31s\n",
      "454:\tlearn: 2.3661097\ttotal: 6m 16s\tremaining: 7m 30s\n",
      "455:\tlearn: 2.3652289\ttotal: 6m 17s\tremaining: 7m 29s\n",
      "456:\tlearn: 2.3646356\ttotal: 6m 17s\tremaining: 7m 28s\n",
      "457:\tlearn: 2.3646328\ttotal: 6m 18s\tremaining: 7m 27s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458:\tlearn: 2.3637472\ttotal: 6m 19s\tremaining: 7m 26s\n",
      "459:\tlearn: 2.3626929\ttotal: 6m 19s\tremaining: 7m 25s\n",
      "460:\tlearn: 2.3622526\ttotal: 6m 20s\tremaining: 7m 25s\n",
      "461:\tlearn: 2.3619835\ttotal: 6m 21s\tremaining: 7m 24s\n",
      "462:\tlearn: 2.3609773\ttotal: 6m 22s\tremaining: 7m 23s\n",
      "463:\tlearn: 2.3605451\ttotal: 6m 23s\tremaining: 7m 22s\n",
      "464:\tlearn: 2.3605438\ttotal: 6m 23s\tremaining: 7m 21s\n",
      "465:\tlearn: 2.3599149\ttotal: 6m 24s\tremaining: 7m 20s\n",
      "466:\tlearn: 2.3595725\ttotal: 6m 25s\tremaining: 7m 19s\n",
      "467:\tlearn: 2.3595697\ttotal: 6m 25s\tremaining: 7m 18s\n",
      "468:\tlearn: 2.3585449\ttotal: 6m 26s\tremaining: 7m 17s\n",
      "469:\tlearn: 2.3576269\ttotal: 6m 27s\tremaining: 7m 16s\n",
      "470:\tlearn: 2.3570040\ttotal: 6m 28s\tremaining: 7m 15s\n",
      "471:\tlearn: 2.3569996\ttotal: 6m 28s\tremaining: 7m 15s\n",
      "472:\tlearn: 2.3565566\ttotal: 6m 29s\tremaining: 7m 14s\n",
      "473:\tlearn: 2.3565538\ttotal: 6m 30s\tremaining: 7m 13s\n",
      "474:\tlearn: 2.3565526\ttotal: 6m 30s\tremaining: 7m 12s\n",
      "475:\tlearn: 2.3553393\ttotal: 6m 31s\tremaining: 7m 11s\n",
      "476:\tlearn: 2.3552538\ttotal: 6m 32s\tremaining: 7m 10s\n",
      "477:\tlearn: 2.3542759\ttotal: 6m 33s\tremaining: 7m 9s\n",
      "478:\tlearn: 2.3530328\ttotal: 6m 34s\tremaining: 7m 8s\n",
      "479:\tlearn: 2.3522918\ttotal: 6m 34s\tremaining: 7m 7s\n",
      "480:\tlearn: 2.3516448\ttotal: 6m 35s\tremaining: 7m 7s\n",
      "481:\tlearn: 2.3507812\ttotal: 6m 36s\tremaining: 7m 6s\n",
      "482:\tlearn: 2.3507775\ttotal: 6m 37s\tremaining: 7m 5s\n",
      "483:\tlearn: 2.3507754\ttotal: 6m 38s\tremaining: 7m 4s\n",
      "484:\tlearn: 2.3504091\ttotal: 6m 39s\tremaining: 7m 4s\n",
      "485:\tlearn: 2.3494674\ttotal: 6m 40s\tremaining: 7m 3s\n",
      "486:\tlearn: 2.3492746\ttotal: 6m 41s\tremaining: 7m 2s\n",
      "487:\tlearn: 2.3488193\ttotal: 6m 41s\tremaining: 7m 1s\n",
      "488:\tlearn: 2.3487738\ttotal: 6m 42s\tremaining: 7m\n",
      "489:\tlearn: 2.3487700\ttotal: 6m 43s\tremaining: 6m 59s\n",
      "490:\tlearn: 2.3478577\ttotal: 6m 44s\tremaining: 6m 59s\n",
      "491:\tlearn: 2.3468874\ttotal: 6m 45s\tremaining: 6m 58s\n",
      "492:\tlearn: 2.3466673\ttotal: 6m 45s\tremaining: 6m 57s\n",
      "493:\tlearn: 2.3458600\ttotal: 6m 46s\tremaining: 6m 56s\n",
      "494:\tlearn: 2.3458111\ttotal: 6m 47s\tremaining: 6m 56s\n",
      "495:\tlearn: 2.3442335\ttotal: 6m 48s\tremaining: 6m 55s\n",
      "496:\tlearn: 2.3432184\ttotal: 6m 49s\tremaining: 6m 54s\n",
      "497:\tlearn: 2.3430857\ttotal: 6m 50s\tremaining: 6m 53s\n",
      "498:\tlearn: 2.3423383\ttotal: 6m 50s\tremaining: 6m 52s\n",
      "499:\tlearn: 2.3422694\ttotal: 6m 51s\tremaining: 6m 51s\n",
      "500:\tlearn: 2.3421196\ttotal: 6m 52s\tremaining: 6m 50s\n",
      "501:\tlearn: 2.3407882\ttotal: 6m 53s\tremaining: 6m 50s\n",
      "502:\tlearn: 2.3399849\ttotal: 6m 54s\tremaining: 6m 49s\n",
      "503:\tlearn: 2.3388126\ttotal: 6m 55s\tremaining: 6m 48s\n",
      "504:\tlearn: 2.3385465\ttotal: 6m 56s\tremaining: 6m 48s\n",
      "505:\tlearn: 2.3368655\ttotal: 6m 56s\tremaining: 6m 47s\n",
      "506:\tlearn: 2.3350665\ttotal: 6m 57s\tremaining: 6m 46s\n",
      "507:\tlearn: 2.3348614\ttotal: 6m 58s\tremaining: 6m 45s\n",
      "508:\tlearn: 2.3344841\ttotal: 6m 59s\tremaining: 6m 44s\n",
      "509:\tlearn: 2.3337973\ttotal: 7m\tremaining: 6m 43s\n",
      "510:\tlearn: 2.3326028\ttotal: 7m\tremaining: 6m 42s\n",
      "511:\tlearn: 2.3311322\ttotal: 7m 2s\tremaining: 6m 42s\n",
      "512:\tlearn: 2.3303888\ttotal: 7m 3s\tremaining: 6m 41s\n",
      "513:\tlearn: 2.3302175\ttotal: 7m 3s\tremaining: 6m 40s\n",
      "514:\tlearn: 2.3301709\ttotal: 7m 4s\tremaining: 6m 40s\n",
      "515:\tlearn: 2.3292719\ttotal: 7m 5s\tremaining: 6m 39s\n",
      "516:\tlearn: 2.3285193\ttotal: 7m 6s\tremaining: 6m 38s\n",
      "517:\tlearn: 2.3283669\ttotal: 7m 7s\tremaining: 6m 37s\n",
      "518:\tlearn: 2.3270834\ttotal: 7m 8s\tremaining: 6m 36s\n",
      "519:\tlearn: 2.3266696\ttotal: 7m 8s\tremaining: 6m 35s\n",
      "520:\tlearn: 2.3264734\ttotal: 7m 9s\tremaining: 6m 35s\n",
      "521:\tlearn: 2.3258860\ttotal: 7m 10s\tremaining: 6m 34s\n",
      "522:\tlearn: 2.3258342\ttotal: 7m 11s\tremaining: 6m 33s\n",
      "523:\tlearn: 2.3248478\ttotal: 7m 12s\tremaining: 6m 32s\n",
      "524:\tlearn: 2.3247622\ttotal: 7m 13s\tremaining: 6m 32s\n",
      "525:\tlearn: 2.3240119\ttotal: 7m 14s\tremaining: 6m 31s\n",
      "526:\tlearn: 2.3231612\ttotal: 7m 14s\tremaining: 6m 30s\n",
      "527:\tlearn: 2.3218263\ttotal: 7m 15s\tremaining: 6m 29s\n",
      "528:\tlearn: 2.3210513\ttotal: 7m 16s\tremaining: 6m 28s\n",
      "529:\tlearn: 2.3208252\ttotal: 7m 17s\tremaining: 6m 27s\n",
      "530:\tlearn: 2.3203447\ttotal: 7m 18s\tremaining: 6m 26s\n",
      "531:\tlearn: 2.3197265\ttotal: 7m 18s\tremaining: 6m 26s\n",
      "532:\tlearn: 2.3194486\ttotal: 7m 19s\tremaining: 6m 25s\n",
      "533:\tlearn: 2.3193375\ttotal: 7m 20s\tremaining: 6m 24s\n",
      "534:\tlearn: 2.3188011\ttotal: 7m 21s\tremaining: 6m 23s\n",
      "535:\tlearn: 2.3187069\ttotal: 7m 22s\tremaining: 6m 22s\n",
      "536:\tlearn: 2.3179379\ttotal: 7m 23s\tremaining: 6m 22s\n",
      "537:\tlearn: 2.3178681\ttotal: 7m 23s\tremaining: 6m 21s\n",
      "538:\tlearn: 2.3167826\ttotal: 7m 24s\tremaining: 6m 20s\n",
      "539:\tlearn: 2.3156641\ttotal: 7m 25s\tremaining: 6m 19s\n",
      "540:\tlearn: 2.3156106\ttotal: 7m 26s\tremaining: 6m 18s\n",
      "541:\tlearn: 2.3155333\ttotal: 7m 27s\tremaining: 6m 17s\n",
      "542:\tlearn: 2.3147925\ttotal: 7m 28s\tremaining: 6m 17s\n",
      "543:\tlearn: 2.3146688\ttotal: 7m 29s\tremaining: 6m 16s\n",
      "544:\tlearn: 2.3146670\ttotal: 7m 29s\tremaining: 6m 15s\n",
      "545:\tlearn: 2.3141459\ttotal: 7m 30s\tremaining: 6m 14s\n",
      "546:\tlearn: 2.3139792\ttotal: 7m 31s\tremaining: 6m 14s\n",
      "547:\tlearn: 2.3139755\ttotal: 7m 32s\tremaining: 6m 13s\n",
      "548:\tlearn: 2.3139744\ttotal: 7m 32s\tremaining: 6m 12s\n",
      "549:\tlearn: 2.3135838\ttotal: 7m 33s\tremaining: 6m 11s\n",
      "550:\tlearn: 2.3132923\ttotal: 7m 34s\tremaining: 6m 10s\n",
      "551:\tlearn: 2.3128561\ttotal: 7m 35s\tremaining: 6m 9s\n",
      "552:\tlearn: 2.3127732\ttotal: 7m 36s\tremaining: 6m 8s\n",
      "553:\tlearn: 2.3120812\ttotal: 7m 37s\tremaining: 6m 8s\n",
      "554:\tlearn: 2.3112108\ttotal: 7m 38s\tremaining: 6m 7s\n",
      "555:\tlearn: 2.3107658\ttotal: 7m 38s\tremaining: 6m 6s\n",
      "556:\tlearn: 2.3104571\ttotal: 7m 39s\tremaining: 6m 5s\n",
      "557:\tlearn: 2.3094558\ttotal: 7m 40s\tremaining: 6m 4s\n",
      "558:\tlearn: 2.3093092\ttotal: 7m 41s\tremaining: 6m 3s\n",
      "559:\tlearn: 2.3093066\ttotal: 7m 42s\tremaining: 6m 3s\n",
      "560:\tlearn: 2.3092951\ttotal: 7m 42s\tremaining: 6m 1s\n",
      "561:\tlearn: 2.3079478\ttotal: 7m 43s\tremaining: 6m 1s\n",
      "562:\tlearn: 2.3071374\ttotal: 7m 44s\tremaining: 6m\n",
      "563:\tlearn: 2.3070962\ttotal: 7m 45s\tremaining: 5m 59s\n",
      "564:\tlearn: 2.3069318\ttotal: 7m 45s\tremaining: 5m 58s\n",
      "565:\tlearn: 2.3062214\ttotal: 7m 46s\tremaining: 5m 57s\n",
      "566:\tlearn: 2.3061234\ttotal: 7m 47s\tremaining: 5m 57s\n",
      "567:\tlearn: 2.3055837\ttotal: 7m 48s\tremaining: 5m 56s\n",
      "568:\tlearn: 2.3048397\ttotal: 7m 49s\tremaining: 5m 55s\n",
      "569:\tlearn: 2.3041329\ttotal: 7m 50s\tremaining: 5m 54s\n",
      "570:\tlearn: 2.3030830\ttotal: 7m 50s\tremaining: 5m 53s\n",
      "571:\tlearn: 2.3023392\ttotal: 7m 52s\tremaining: 5m 53s\n",
      "572:\tlearn: 2.3020230\ttotal: 7m 53s\tremaining: 5m 52s\n",
      "573:\tlearn: 2.3010907\ttotal: 7m 53s\tremaining: 5m 51s\n",
      "574:\tlearn: 2.3010705\ttotal: 7m 54s\tremaining: 5m 50s\n",
      "575:\tlearn: 2.3000422\ttotal: 7m 55s\tremaining: 5m 50s\n",
      "576:\tlearn: 2.2989008\ttotal: 7m 56s\tremaining: 5m 49s\n",
      "577:\tlearn: 2.2982035\ttotal: 7m 57s\tremaining: 5m 48s\n",
      "578:\tlearn: 2.2980143\ttotal: 7m 57s\tremaining: 5m 47s\n",
      "579:\tlearn: 2.2973093\ttotal: 7m 58s\tremaining: 5m 46s\n",
      "580:\tlearn: 2.2972596\ttotal: 7m 59s\tremaining: 5m 45s\n",
      "581:\tlearn: 2.2964656\ttotal: 8m\tremaining: 5m 45s\n",
      "582:\tlearn: 2.2954898\ttotal: 8m 1s\tremaining: 5m 44s\n",
      "583:\tlearn: 2.2949707\ttotal: 8m 2s\tremaining: 5m 43s\n",
      "584:\tlearn: 2.2935886\ttotal: 8m 3s\tremaining: 5m 42s\n",
      "585:\tlearn: 2.2933982\ttotal: 8m 3s\tremaining: 5m 41s\n",
      "586:\tlearn: 2.2933511\ttotal: 8m 4s\tremaining: 5m 40s\n",
      "587:\tlearn: 2.2926452\ttotal: 8m 5s\tremaining: 5m 40s\n",
      "588:\tlearn: 2.2921694\ttotal: 8m 6s\tremaining: 5m 39s\n",
      "589:\tlearn: 2.2914206\ttotal: 8m 7s\tremaining: 5m 38s\n",
      "590:\tlearn: 2.2905779\ttotal: 8m 8s\tremaining: 5m 37s\n",
      "591:\tlearn: 2.2899551\ttotal: 8m 8s\tremaining: 5m 37s\n",
      "592:\tlearn: 2.2887870\ttotal: 8m 9s\tremaining: 5m 36s\n",
      "593:\tlearn: 2.2879456\ttotal: 8m 10s\tremaining: 5m 35s\n",
      "594:\tlearn: 2.2877962\ttotal: 8m 11s\tremaining: 5m 34s\n",
      "595:\tlearn: 2.2876208\ttotal: 8m 12s\tremaining: 5m 33s\n",
      "596:\tlearn: 2.2868663\ttotal: 8m 12s\tremaining: 5m 32s\n",
      "597:\tlearn: 2.2857554\ttotal: 8m 13s\tremaining: 5m 31s\n",
      "598:\tlearn: 2.2850768\ttotal: 8m 14s\tremaining: 5m 31s\n",
      "599:\tlearn: 2.2841382\ttotal: 8m 15s\tremaining: 5m 30s\n",
      "600:\tlearn: 2.2836948\ttotal: 8m 16s\tremaining: 5m 29s\n",
      "601:\tlearn: 2.2835315\ttotal: 8m 17s\tremaining: 5m 28s\n",
      "602:\tlearn: 2.2833343\ttotal: 8m 18s\tremaining: 5m 28s\n",
      "603:\tlearn: 2.2831455\ttotal: 8m 19s\tremaining: 5m 27s\n",
      "604:\tlearn: 2.2822550\ttotal: 8m 19s\tremaining: 5m 26s\n",
      "605:\tlearn: 2.2821067\ttotal: 8m 20s\tremaining: 5m 25s\n",
      "606:\tlearn: 2.2812309\ttotal: 8m 21s\tremaining: 5m 24s\n",
      "607:\tlearn: 2.2809711\ttotal: 8m 22s\tremaining: 5m 23s\n",
      "608:\tlearn: 2.2806079\ttotal: 8m 23s\tremaining: 5m 23s\n",
      "609:\tlearn: 2.2805523\ttotal: 8m 24s\tremaining: 5m 22s\n",
      "610:\tlearn: 2.2796376\ttotal: 8m 25s\tremaining: 5m 21s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "611:\tlearn: 2.2784236\ttotal: 8m 26s\tremaining: 5m 20s\n",
      "612:\tlearn: 2.2771671\ttotal: 8m 27s\tremaining: 5m 20s\n",
      "613:\tlearn: 2.2768924\ttotal: 8m 28s\tremaining: 5m 19s\n",
      "614:\tlearn: 2.2763767\ttotal: 8m 30s\tremaining: 5m 19s\n",
      "615:\tlearn: 2.2756902\ttotal: 8m 32s\tremaining: 5m 19s\n",
      "616:\tlearn: 2.2753007\ttotal: 8m 33s\tremaining: 5m 18s\n",
      "617:\tlearn: 2.2744044\ttotal: 8m 34s\tremaining: 5m 18s\n",
      "618:\tlearn: 2.2736858\ttotal: 8m 35s\tremaining: 5m 17s\n",
      "619:\tlearn: 2.2736839\ttotal: 8m 36s\tremaining: 5m 16s\n",
      "620:\tlearn: 2.2736650\ttotal: 8m 37s\tremaining: 5m 15s\n",
      "621:\tlearn: 2.2725787\ttotal: 8m 38s\tremaining: 5m 14s\n",
      "622:\tlearn: 2.2724327\ttotal: 8m 38s\tremaining: 5m 13s\n",
      "623:\tlearn: 2.2720883\ttotal: 8m 39s\tremaining: 5m 13s\n",
      "624:\tlearn: 2.2712552\ttotal: 8m 40s\tremaining: 5m 12s\n",
      "625:\tlearn: 2.2704479\ttotal: 8m 41s\tremaining: 5m 11s\n",
      "626:\tlearn: 2.2700336\ttotal: 8m 42s\tremaining: 5m 10s\n",
      "627:\tlearn: 2.2699912\ttotal: 8m 43s\tremaining: 5m 10s\n",
      "628:\tlearn: 2.2691625\ttotal: 8m 44s\tremaining: 5m 9s\n",
      "629:\tlearn: 2.2673891\ttotal: 8m 44s\tremaining: 5m 8s\n",
      "630:\tlearn: 2.2670095\ttotal: 8m 45s\tremaining: 5m 7s\n",
      "631:\tlearn: 2.2666553\ttotal: 8m 46s\tremaining: 5m 6s\n",
      "632:\tlearn: 2.2661573\ttotal: 8m 47s\tremaining: 5m 5s\n",
      "633:\tlearn: 2.2660690\ttotal: 8m 48s\tremaining: 5m 4s\n",
      "634:\tlearn: 2.2651730\ttotal: 8m 49s\tremaining: 5m 4s\n",
      "635:\tlearn: 2.2649249\ttotal: 8m 50s\tremaining: 5m 3s\n",
      "636:\tlearn: 2.2641438\ttotal: 8m 50s\tremaining: 5m 2s\n",
      "637:\tlearn: 2.2637253\ttotal: 8m 51s\tremaining: 5m 1s\n",
      "638:\tlearn: 2.2630365\ttotal: 8m 52s\tremaining: 5m\n",
      "639:\tlearn: 2.2627978\ttotal: 8m 53s\tremaining: 4m 59s\n",
      "640:\tlearn: 2.2620991\ttotal: 8m 54s\tremaining: 4m 59s\n",
      "641:\tlearn: 2.2605477\ttotal: 8m 54s\tremaining: 4m 58s\n",
      "642:\tlearn: 2.2601572\ttotal: 8m 55s\tremaining: 4m 57s\n",
      "643:\tlearn: 2.2598785\ttotal: 8m 56s\tremaining: 4m 56s\n",
      "644:\tlearn: 2.2592394\ttotal: 8m 57s\tremaining: 4m 55s\n",
      "645:\tlearn: 2.2591980\ttotal: 8m 58s\tremaining: 4m 54s\n",
      "646:\tlearn: 2.2591853\ttotal: 8m 59s\tremaining: 4m 54s\n",
      "647:\tlearn: 2.2584260\ttotal: 8m 59s\tremaining: 4m 53s\n",
      "648:\tlearn: 2.2581221\ttotal: 9m\tremaining: 4m 52s\n",
      "649:\tlearn: 2.2579238\ttotal: 9m 1s\tremaining: 4m 51s\n",
      "650:\tlearn: 2.2565822\ttotal: 9m 2s\tremaining: 4m 50s\n",
      "651:\tlearn: 2.2561620\ttotal: 9m 3s\tremaining: 4m 49s\n",
      "652:\tlearn: 2.2556435\ttotal: 9m 4s\tremaining: 4m 49s\n",
      "653:\tlearn: 2.2541875\ttotal: 9m 5s\tremaining: 4m 48s\n",
      "654:\tlearn: 2.2538196\ttotal: 9m 5s\tremaining: 4m 47s\n",
      "655:\tlearn: 2.2536778\ttotal: 9m 6s\tremaining: 4m 46s\n",
      "656:\tlearn: 2.2532221\ttotal: 9m 7s\tremaining: 4m 45s\n",
      "657:\tlearn: 2.2526381\ttotal: 9m 8s\tremaining: 4m 44s\n",
      "658:\tlearn: 2.2518417\ttotal: 9m 9s\tremaining: 4m 44s\n",
      "659:\tlearn: 2.2511829\ttotal: 9m 9s\tremaining: 4m 43s\n",
      "660:\tlearn: 2.2507581\ttotal: 9m 10s\tremaining: 4m 42s\n",
      "661:\tlearn: 2.2507258\ttotal: 9m 11s\tremaining: 4m 41s\n",
      "662:\tlearn: 2.2497886\ttotal: 9m 12s\tremaining: 4m 40s\n",
      "663:\tlearn: 2.2494931\ttotal: 9m 13s\tremaining: 4m 40s\n",
      "664:\tlearn: 2.2491176\ttotal: 9m 14s\tremaining: 4m 39s\n",
      "665:\tlearn: 2.2488254\ttotal: 9m 15s\tremaining: 4m 38s\n",
      "666:\tlearn: 2.2482585\ttotal: 9m 16s\tremaining: 4m 37s\n",
      "667:\tlearn: 2.2478696\ttotal: 9m 17s\tremaining: 4m 36s\n",
      "668:\tlearn: 2.2467264\ttotal: 9m 17s\tremaining: 4m 36s\n",
      "669:\tlearn: 2.2459983\ttotal: 9m 18s\tremaining: 4m 35s\n",
      "670:\tlearn: 2.2457422\ttotal: 9m 19s\tremaining: 4m 34s\n",
      "671:\tlearn: 2.2450574\ttotal: 9m 20s\tremaining: 4m 33s\n",
      "672:\tlearn: 2.2446472\ttotal: 9m 21s\tremaining: 4m 32s\n",
      "673:\tlearn: 2.2446306\ttotal: 9m 22s\tremaining: 4m 31s\n",
      "674:\tlearn: 2.2436127\ttotal: 9m 23s\tremaining: 4m 31s\n",
      "675:\tlearn: 2.2434957\ttotal: 9m 23s\tremaining: 4m 30s\n",
      "676:\tlearn: 2.2423369\ttotal: 9m 24s\tremaining: 4m 29s\n",
      "677:\tlearn: 2.2415322\ttotal: 9m 25s\tremaining: 4m 28s\n",
      "678:\tlearn: 2.2408992\ttotal: 9m 26s\tremaining: 4m 27s\n",
      "679:\tlearn: 2.2401509\ttotal: 9m 26s\tremaining: 4m 26s\n",
      "680:\tlearn: 2.2400861\ttotal: 9m 27s\tremaining: 4m 26s\n",
      "681:\tlearn: 2.2396620\ttotal: 9m 29s\tremaining: 4m 25s\n",
      "682:\tlearn: 2.2386977\ttotal: 9m 30s\tremaining: 4m 24s\n",
      "683:\tlearn: 2.2380231\ttotal: 9m 31s\tremaining: 4m 23s\n",
      "684:\tlearn: 2.2374232\ttotal: 9m 31s\tremaining: 4m 22s\n",
      "685:\tlearn: 2.2370001\ttotal: 9m 32s\tremaining: 4m 22s\n",
      "686:\tlearn: 2.2369017\ttotal: 9m 33s\tremaining: 4m 21s\n",
      "687:\tlearn: 2.2361952\ttotal: 9m 34s\tremaining: 4m 20s\n",
      "688:\tlearn: 2.2353516\ttotal: 9m 34s\tremaining: 4m 19s\n",
      "689:\tlearn: 2.2346691\ttotal: 9m 35s\tremaining: 4m 18s\n",
      "690:\tlearn: 2.2345372\ttotal: 9m 36s\tremaining: 4m 17s\n",
      "691:\tlearn: 2.2345010\ttotal: 9m 36s\tremaining: 4m 16s\n",
      "692:\tlearn: 2.2342097\ttotal: 9m 37s\tremaining: 4m 15s\n",
      "693:\tlearn: 2.2327435\ttotal: 9m 38s\tremaining: 4m 15s\n",
      "694:\tlearn: 2.2323286\ttotal: 9m 39s\tremaining: 4m 14s\n",
      "695:\tlearn: 2.2316603\ttotal: 9m 40s\tremaining: 4m 13s\n",
      "696:\tlearn: 2.2312492\ttotal: 9m 41s\tremaining: 4m 12s\n",
      "697:\tlearn: 2.2307350\ttotal: 9m 41s\tremaining: 4m 11s\n",
      "698:\tlearn: 2.2302967\ttotal: 9m 42s\tremaining: 4m 10s\n",
      "699:\tlearn: 2.2300462\ttotal: 9m 44s\tremaining: 4m 10s\n",
      "700:\tlearn: 2.2294663\ttotal: 9m 45s\tremaining: 4m 9s\n",
      "701:\tlearn: 2.2292557\ttotal: 9m 47s\tremaining: 4m 9s\n",
      "702:\tlearn: 2.2287024\ttotal: 9m 48s\tremaining: 4m 8s\n",
      "703:\tlearn: 2.2278377\ttotal: 9m 49s\tremaining: 4m 7s\n",
      "704:\tlearn: 2.2260005\ttotal: 9m 50s\tremaining: 4m 7s\n",
      "705:\tlearn: 2.2256158\ttotal: 9m 51s\tremaining: 4m 6s\n",
      "706:\tlearn: 2.2252781\ttotal: 9m 52s\tremaining: 4m 5s\n",
      "707:\tlearn: 2.2252621\ttotal: 9m 52s\tremaining: 4m 4s\n",
      "708:\tlearn: 2.2250355\ttotal: 9m 53s\tremaining: 4m 3s\n",
      "709:\tlearn: 2.2241947\ttotal: 9m 54s\tremaining: 4m 2s\n",
      "710:\tlearn: 2.2233235\ttotal: 9m 55s\tremaining: 4m 2s\n",
      "711:\tlearn: 2.2224790\ttotal: 9m 56s\tremaining: 4m 1s\n",
      "712:\tlearn: 2.2215018\ttotal: 9m 57s\tremaining: 4m\n",
      "713:\tlearn: 2.2209390\ttotal: 9m 58s\tremaining: 3m 59s\n",
      "714:\tlearn: 2.2206632\ttotal: 9m 58s\tremaining: 3m 58s\n",
      "715:\tlearn: 2.2189166\ttotal: 9m 59s\tremaining: 3m 57s\n",
      "716:\tlearn: 2.2181262\ttotal: 10m\tremaining: 3m 56s\n",
      "717:\tlearn: 2.2180510\ttotal: 10m 1s\tremaining: 3m 56s\n",
      "718:\tlearn: 2.2179438\ttotal: 10m 1s\tremaining: 3m 55s\n",
      "719:\tlearn: 2.2176201\ttotal: 10m 2s\tremaining: 3m 54s\n",
      "720:\tlearn: 2.2171093\ttotal: 10m 3s\tremaining: 3m 53s\n",
      "721:\tlearn: 2.2168625\ttotal: 10m 4s\tremaining: 3m 52s\n",
      "722:\tlearn: 2.2163365\ttotal: 10m 5s\tremaining: 3m 51s\n",
      "723:\tlearn: 2.2153859\ttotal: 10m 6s\tremaining: 3m 51s\n",
      "724:\tlearn: 2.2153396\ttotal: 10m 6s\tremaining: 3m 50s\n",
      "725:\tlearn: 2.2149635\ttotal: 10m 7s\tremaining: 3m 49s\n",
      "726:\tlearn: 2.2137969\ttotal: 10m 8s\tremaining: 3m 48s\n",
      "727:\tlearn: 2.2137414\ttotal: 10m 9s\tremaining: 3m 47s\n",
      "728:\tlearn: 2.2128961\ttotal: 10m 10s\tremaining: 3m 46s\n",
      "729:\tlearn: 2.2127856\ttotal: 10m 11s\tremaining: 3m 45s\n",
      "730:\tlearn: 2.2126619\ttotal: 10m 11s\tremaining: 3m 45s\n",
      "731:\tlearn: 2.2126398\ttotal: 10m 12s\tremaining: 3m 44s\n",
      "732:\tlearn: 2.2124152\ttotal: 10m 13s\tremaining: 3m 43s\n",
      "733:\tlearn: 2.2124125\ttotal: 10m 14s\tremaining: 3m 42s\n",
      "734:\tlearn: 2.2123147\ttotal: 10m 15s\tremaining: 3m 41s\n",
      "735:\tlearn: 2.2115221\ttotal: 10m 15s\tremaining: 3m 40s\n",
      "736:\tlearn: 2.2114653\ttotal: 10m 16s\tremaining: 3m 40s\n",
      "737:\tlearn: 2.2108679\ttotal: 10m 17s\tremaining: 3m 39s\n",
      "738:\tlearn: 2.2098929\ttotal: 10m 18s\tremaining: 3m 38s\n",
      "739:\tlearn: 2.2097291\ttotal: 10m 19s\tremaining: 3m 37s\n",
      "740:\tlearn: 2.2097070\ttotal: 10m 20s\tremaining: 3m 36s\n",
      "741:\tlearn: 2.2091470\ttotal: 10m 20s\tremaining: 3m 35s\n",
      "742:\tlearn: 2.2090653\ttotal: 10m 21s\tremaining: 3m 35s\n",
      "743:\tlearn: 2.2086836\ttotal: 10m 22s\tremaining: 3m 34s\n",
      "744:\tlearn: 2.2086111\ttotal: 10m 23s\tremaining: 3m 33s\n",
      "745:\tlearn: 2.2084536\ttotal: 10m 23s\tremaining: 3m 32s\n",
      "746:\tlearn: 2.2079286\ttotal: 10m 24s\tremaining: 3m 31s\n",
      "747:\tlearn: 2.2078680\ttotal: 10m 25s\tremaining: 3m 30s\n",
      "748:\tlearn: 2.2078453\ttotal: 10m 26s\tremaining: 3m 29s\n",
      "749:\tlearn: 2.2077899\ttotal: 10m 27s\tremaining: 3m 29s\n",
      "750:\tlearn: 2.2076117\ttotal: 10m 28s\tremaining: 3m 28s\n",
      "751:\tlearn: 2.2073255\ttotal: 10m 29s\tremaining: 3m 27s\n",
      "752:\tlearn: 2.2058412\ttotal: 10m 30s\tremaining: 3m 26s\n",
      "753:\tlearn: 2.2054181\ttotal: 10m 31s\tremaining: 3m 25s\n",
      "754:\tlearn: 2.2052118\ttotal: 10m 32s\tremaining: 3m 25s\n",
      "755:\tlearn: 2.2043593\ttotal: 10m 32s\tremaining: 3m 24s\n",
      "756:\tlearn: 2.2037380\ttotal: 10m 33s\tremaining: 3m 23s\n",
      "757:\tlearn: 2.2034667\ttotal: 10m 34s\tremaining: 3m 22s\n",
      "758:\tlearn: 2.2032967\ttotal: 10m 35s\tremaining: 3m 21s\n",
      "759:\tlearn: 2.2024548\ttotal: 10m 36s\tremaining: 3m 20s\n",
      "760:\tlearn: 2.2018402\ttotal: 10m 37s\tremaining: 3m 20s\n",
      "761:\tlearn: 2.2018293\ttotal: 10m 38s\tremaining: 3m 19s\n",
      "762:\tlearn: 2.2013132\ttotal: 10m 38s\tremaining: 3m 18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763:\tlearn: 2.2012686\ttotal: 10m 39s\tremaining: 3m 17s\n",
      "764:\tlearn: 2.2010571\ttotal: 10m 40s\tremaining: 3m 16s\n",
      "765:\tlearn: 2.2009091\ttotal: 10m 41s\tremaining: 3m 15s\n",
      "766:\tlearn: 2.2008573\ttotal: 10m 41s\tremaining: 3m 14s\n",
      "767:\tlearn: 2.2007036\ttotal: 10m 42s\tremaining: 3m 14s\n",
      "768:\tlearn: 2.2004297\ttotal: 10m 43s\tremaining: 3m 13s\n",
      "769:\tlearn: 2.2003593\ttotal: 10m 44s\tremaining: 3m 12s\n",
      "770:\tlearn: 2.1995693\ttotal: 10m 45s\tremaining: 3m 11s\n",
      "771:\tlearn: 2.1994775\ttotal: 10m 46s\tremaining: 3m 10s\n",
      "772:\tlearn: 2.1983498\ttotal: 10m 46s\tremaining: 3m 9s\n",
      "773:\tlearn: 2.1982625\ttotal: 10m 47s\tremaining: 3m 9s\n",
      "774:\tlearn: 2.1974913\ttotal: 10m 48s\tremaining: 3m 8s\n",
      "775:\tlearn: 2.1961932\ttotal: 10m 49s\tremaining: 3m 7s\n",
      "776:\tlearn: 2.1958911\ttotal: 10m 50s\tremaining: 3m 6s\n",
      "777:\tlearn: 2.1950834\ttotal: 10m 50s\tremaining: 3m 5s\n",
      "778:\tlearn: 2.1950826\ttotal: 10m 51s\tremaining: 3m 4s\n",
      "779:\tlearn: 2.1948536\ttotal: 10m 52s\tremaining: 3m 4s\n",
      "780:\tlearn: 2.1943175\ttotal: 10m 53s\tremaining: 3m 3s\n",
      "781:\tlearn: 2.1942891\ttotal: 10m 54s\tremaining: 3m 2s\n",
      "782:\tlearn: 2.1941765\ttotal: 10m 55s\tremaining: 3m 1s\n",
      "783:\tlearn: 2.1941744\ttotal: 10m 55s\tremaining: 3m\n",
      "784:\tlearn: 2.1931574\ttotal: 10m 56s\tremaining: 2m 59s\n",
      "785:\tlearn: 2.1924207\ttotal: 10m 57s\tremaining: 2m 59s\n",
      "786:\tlearn: 2.1923869\ttotal: 10m 58s\tremaining: 2m 58s\n",
      "787:\tlearn: 2.1921832\ttotal: 10m 59s\tremaining: 2m 57s\n",
      "788:\tlearn: 2.1921797\ttotal: 11m\tremaining: 2m 56s\n",
      "789:\tlearn: 2.1910378\ttotal: 11m 1s\tremaining: 2m 55s\n",
      "790:\tlearn: 2.1909855\ttotal: 11m 2s\tremaining: 2m 54s\n",
      "791:\tlearn: 2.1908876\ttotal: 11m 2s\tremaining: 2m 54s\n",
      "792:\tlearn: 2.1905883\ttotal: 11m 3s\tremaining: 2m 53s\n",
      "793:\tlearn: 2.1905649\ttotal: 11m 4s\tremaining: 2m 52s\n",
      "794:\tlearn: 2.1902891\ttotal: 11m 5s\tremaining: 2m 51s\n",
      "795:\tlearn: 2.1893304\ttotal: 11m 6s\tremaining: 2m 50s\n",
      "796:\tlearn: 2.1885547\ttotal: 11m 7s\tremaining: 2m 49s\n",
      "797:\tlearn: 2.1874407\ttotal: 11m 8s\tremaining: 2m 49s\n",
      "798:\tlearn: 2.1871059\ttotal: 11m 8s\tremaining: 2m 48s\n",
      "799:\tlearn: 2.1868071\ttotal: 11m 9s\tremaining: 2m 47s\n",
      "800:\tlearn: 2.1867466\ttotal: 11m 10s\tremaining: 2m 46s\n",
      "801:\tlearn: 2.1862171\ttotal: 11m 11s\tremaining: 2m 45s\n",
      "802:\tlearn: 2.1858523\ttotal: 11m 12s\tremaining: 2m 44s\n",
      "803:\tlearn: 2.1857039\ttotal: 11m 12s\tremaining: 2m 44s\n",
      "804:\tlearn: 2.1853610\ttotal: 11m 13s\tremaining: 2m 43s\n",
      "805:\tlearn: 2.1852502\ttotal: 11m 14s\tremaining: 2m 42s\n",
      "806:\tlearn: 2.1851817\ttotal: 11m 15s\tremaining: 2m 41s\n",
      "807:\tlearn: 2.1843383\ttotal: 11m 16s\tremaining: 2m 40s\n",
      "808:\tlearn: 2.1842970\ttotal: 11m 17s\tremaining: 2m 39s\n",
      "809:\tlearn: 2.1841440\ttotal: 11m 18s\tremaining: 2m 39s\n",
      "810:\tlearn: 2.1832577\ttotal: 11m 18s\tremaining: 2m 38s\n",
      "811:\tlearn: 2.1831088\ttotal: 11m 20s\tremaining: 2m 37s\n",
      "812:\tlearn: 2.1824629\ttotal: 11m 21s\tremaining: 2m 36s\n",
      "813:\tlearn: 2.1821786\ttotal: 11m 22s\tremaining: 2m 35s\n",
      "814:\tlearn: 2.1821699\ttotal: 11m 23s\tremaining: 2m 35s\n",
      "815:\tlearn: 2.1819560\ttotal: 11m 25s\tremaining: 2m 34s\n",
      "816:\tlearn: 2.1815581\ttotal: 11m 27s\tremaining: 2m 33s\n",
      "817:\tlearn: 2.1809571\ttotal: 11m 27s\tremaining: 2m 33s\n",
      "818:\tlearn: 2.1807810\ttotal: 11m 28s\tremaining: 2m 32s\n",
      "819:\tlearn: 2.1804991\ttotal: 11m 29s\tremaining: 2m 31s\n",
      "820:\tlearn: 2.1792027\ttotal: 11m 30s\tremaining: 2m 30s\n",
      "821:\tlearn: 2.1790783\ttotal: 11m 31s\tremaining: 2m 29s\n",
      "822:\tlearn: 2.1790416\ttotal: 11m 32s\tremaining: 2m 29s\n",
      "823:\tlearn: 2.1776747\ttotal: 11m 33s\tremaining: 2m 28s\n",
      "824:\tlearn: 2.1768519\ttotal: 11m 35s\tremaining: 2m 27s\n",
      "825:\tlearn: 2.1768041\ttotal: 11m 36s\tremaining: 2m 26s\n",
      "826:\tlearn: 2.1766846\ttotal: 11m 36s\tremaining: 2m 25s\n",
      "827:\tlearn: 2.1760076\ttotal: 11m 37s\tremaining: 2m 24s\n",
      "828:\tlearn: 2.1753401\ttotal: 11m 38s\tremaining: 2m 24s\n",
      "829:\tlearn: 2.1753182\ttotal: 11m 39s\tremaining: 2m 23s\n",
      "830:\tlearn: 2.1749276\ttotal: 11m 40s\tremaining: 2m 22s\n",
      "831:\tlearn: 2.1745540\ttotal: 11m 41s\tremaining: 2m 21s\n",
      "832:\tlearn: 2.1743698\ttotal: 11m 42s\tremaining: 2m 20s\n",
      "833:\tlearn: 2.1736474\ttotal: 11m 43s\tremaining: 2m 19s\n",
      "834:\tlearn: 2.1726927\ttotal: 11m 43s\tremaining: 2m 19s\n",
      "835:\tlearn: 2.1723777\ttotal: 11m 44s\tremaining: 2m 18s\n",
      "836:\tlearn: 2.1722178\ttotal: 11m 45s\tremaining: 2m 17s\n",
      "837:\tlearn: 2.1715743\ttotal: 11m 46s\tremaining: 2m 16s\n",
      "838:\tlearn: 2.1715309\ttotal: 11m 47s\tremaining: 2m 15s\n",
      "839:\tlearn: 2.1712412\ttotal: 11m 47s\tremaining: 2m 14s\n",
      "840:\tlearn: 2.1712370\ttotal: 11m 48s\tremaining: 2m 14s\n",
      "841:\tlearn: 2.1708317\ttotal: 11m 49s\tremaining: 2m 13s\n",
      "842:\tlearn: 2.1691633\ttotal: 11m 50s\tremaining: 2m 12s\n",
      "843:\tlearn: 2.1689481\ttotal: 11m 51s\tremaining: 2m 11s\n",
      "844:\tlearn: 2.1689146\ttotal: 11m 52s\tremaining: 2m 10s\n",
      "845:\tlearn: 2.1688201\ttotal: 11m 53s\tremaining: 2m 9s\n",
      "846:\tlearn: 2.1683242\ttotal: 11m 53s\tremaining: 2m 8s\n",
      "847:\tlearn: 2.1681162\ttotal: 11m 54s\tremaining: 2m 8s\n",
      "848:\tlearn: 2.1675363\ttotal: 11m 55s\tremaining: 2m 7s\n",
      "849:\tlearn: 2.1665346\ttotal: 11m 56s\tremaining: 2m 6s\n",
      "850:\tlearn: 2.1660057\ttotal: 11m 57s\tremaining: 2m 5s\n",
      "851:\tlearn: 2.1657053\ttotal: 11m 58s\tremaining: 2m 4s\n",
      "852:\tlearn: 2.1653593\ttotal: 11m 59s\tremaining: 2m 3s\n",
      "853:\tlearn: 2.1653030\ttotal: 12m\tremaining: 2m 3s\n",
      "854:\tlearn: 2.1652781\ttotal: 12m 1s\tremaining: 2m 2s\n",
      "855:\tlearn: 2.1650750\ttotal: 12m 1s\tremaining: 2m 1s\n",
      "856:\tlearn: 2.1639981\ttotal: 12m 2s\tremaining: 2m\n",
      "857:\tlearn: 2.1638439\ttotal: 12m 3s\tremaining: 1m 59s\n",
      "858:\tlearn: 2.1637972\ttotal: 12m 4s\tremaining: 1m 58s\n",
      "859:\tlearn: 2.1624240\ttotal: 12m 6s\tremaining: 1m 58s\n",
      "860:\tlearn: 2.1623166\ttotal: 12m 7s\tremaining: 1m 57s\n",
      "861:\tlearn: 2.1617240\ttotal: 12m 9s\tremaining: 1m 56s\n",
      "862:\tlearn: 2.1616863\ttotal: 12m 10s\tremaining: 1m 55s\n",
      "863:\tlearn: 2.1614898\ttotal: 12m 11s\tremaining: 1m 55s\n",
      "864:\tlearn: 2.1614112\ttotal: 12m 12s\tremaining: 1m 54s\n",
      "865:\tlearn: 2.1608850\ttotal: 12m 13s\tremaining: 1m 53s\n",
      "866:\tlearn: 2.1599591\ttotal: 12m 14s\tremaining: 1m 52s\n",
      "867:\tlearn: 2.1596908\ttotal: 12m 15s\tremaining: 1m 51s\n",
      "868:\tlearn: 2.1590812\ttotal: 12m 15s\tremaining: 1m 50s\n",
      "869:\tlearn: 2.1582940\ttotal: 12m 16s\tremaining: 1m 50s\n",
      "870:\tlearn: 2.1576050\ttotal: 12m 17s\tremaining: 1m 49s\n",
      "871:\tlearn: 2.1573436\ttotal: 12m 18s\tremaining: 1m 48s\n",
      "872:\tlearn: 2.1570491\ttotal: 12m 19s\tremaining: 1m 47s\n",
      "873:\tlearn: 2.1568314\ttotal: 12m 20s\tremaining: 1m 46s\n",
      "874:\tlearn: 2.1561981\ttotal: 12m 20s\tremaining: 1m 45s\n",
      "875:\tlearn: 2.1560592\ttotal: 12m 21s\tremaining: 1m 44s\n",
      "876:\tlearn: 2.1555595\ttotal: 12m 22s\tremaining: 1m 44s\n",
      "877:\tlearn: 2.1554345\ttotal: 12m 23s\tremaining: 1m 43s\n",
      "878:\tlearn: 2.1553717\ttotal: 12m 24s\tremaining: 1m 42s\n",
      "879:\tlearn: 2.1549888\ttotal: 12m 25s\tremaining: 1m 41s\n",
      "880:\tlearn: 2.1545406\ttotal: 12m 26s\tremaining: 1m 40s\n",
      "881:\tlearn: 2.1541592\ttotal: 12m 26s\tremaining: 1m 39s\n",
      "882:\tlearn: 2.1540091\ttotal: 12m 27s\tremaining: 1m 39s\n",
      "883:\tlearn: 2.1534016\ttotal: 12m 28s\tremaining: 1m 38s\n",
      "884:\tlearn: 2.1532580\ttotal: 12m 29s\tremaining: 1m 37s\n",
      "885:\tlearn: 2.1530956\ttotal: 12m 30s\tremaining: 1m 36s\n",
      "886:\tlearn: 2.1530157\ttotal: 12m 31s\tremaining: 1m 35s\n",
      "887:\tlearn: 2.1519245\ttotal: 12m 32s\tremaining: 1m 34s\n",
      "888:\tlearn: 2.1518938\ttotal: 12m 33s\tremaining: 1m 34s\n",
      "889:\tlearn: 2.1517851\ttotal: 12m 33s\tremaining: 1m 33s\n",
      "890:\tlearn: 2.1516875\ttotal: 12m 34s\tremaining: 1m 32s\n",
      "891:\tlearn: 2.1515335\ttotal: 12m 35s\tremaining: 1m 31s\n",
      "892:\tlearn: 2.1514771\ttotal: 12m 36s\tremaining: 1m 30s\n",
      "893:\tlearn: 2.1507215\ttotal: 12m 36s\tremaining: 1m 29s\n",
      "894:\tlearn: 2.1507117\ttotal: 12m 37s\tremaining: 1m 28s\n",
      "895:\tlearn: 2.1507039\ttotal: 12m 38s\tremaining: 1m 28s\n",
      "896:\tlearn: 2.1501951\ttotal: 12m 39s\tremaining: 1m 27s\n",
      "897:\tlearn: 2.1493294\ttotal: 12m 40s\tremaining: 1m 26s\n",
      "898:\tlearn: 2.1487412\ttotal: 12m 41s\tremaining: 1m 25s\n",
      "899:\tlearn: 2.1486330\ttotal: 12m 42s\tremaining: 1m 24s\n",
      "900:\tlearn: 2.1482081\ttotal: 12m 42s\tremaining: 1m 23s\n",
      "901:\tlearn: 2.1477485\ttotal: 12m 43s\tremaining: 1m 22s\n",
      "902:\tlearn: 2.1477356\ttotal: 12m 44s\tremaining: 1m 22s\n",
      "903:\tlearn: 2.1477346\ttotal: 12m 45s\tremaining: 1m 21s\n",
      "904:\tlearn: 2.1476299\ttotal: 12m 46s\tremaining: 1m 20s\n",
      "905:\tlearn: 2.1469124\ttotal: 12m 47s\tremaining: 1m 19s\n",
      "906:\tlearn: 2.1463522\ttotal: 12m 48s\tremaining: 1m 18s\n",
      "907:\tlearn: 2.1463275\ttotal: 12m 49s\tremaining: 1m 17s\n",
      "908:\tlearn: 2.1457984\ttotal: 12m 50s\tremaining: 1m 17s\n",
      "909:\tlearn: 2.1444966\ttotal: 12m 51s\tremaining: 1m 16s\n",
      "910:\tlearn: 2.1444581\ttotal: 12m 51s\tremaining: 1m 15s\n",
      "911:\tlearn: 2.1437782\ttotal: 12m 52s\tremaining: 1m 14s\n",
      "912:\tlearn: 2.1432386\ttotal: 12m 53s\tremaining: 1m 13s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "913:\tlearn: 2.1425562\ttotal: 12m 54s\tremaining: 1m 12s\n",
      "914:\tlearn: 2.1425334\ttotal: 12m 54s\tremaining: 1m 11s\n",
      "915:\tlearn: 2.1416560\ttotal: 12m 55s\tremaining: 1m 11s\n",
      "916:\tlearn: 2.1409986\ttotal: 12m 56s\tremaining: 1m 10s\n",
      "917:\tlearn: 2.1402132\ttotal: 12m 57s\tremaining: 1m 9s\n",
      "918:\tlearn: 2.1401072\ttotal: 12m 58s\tremaining: 1m 8s\n",
      "919:\tlearn: 2.1400476\ttotal: 12m 59s\tremaining: 1m 7s\n",
      "920:\tlearn: 2.1393419\ttotal: 13m\tremaining: 1m 6s\n",
      "921:\tlearn: 2.1387499\ttotal: 13m 1s\tremaining: 1m 6s\n",
      "922:\tlearn: 2.1386615\ttotal: 13m 1s\tremaining: 1m 5s\n",
      "923:\tlearn: 2.1383850\ttotal: 13m 2s\tremaining: 1m 4s\n",
      "924:\tlearn: 2.1383425\ttotal: 13m 3s\tremaining: 1m 3s\n",
      "925:\tlearn: 2.1382824\ttotal: 13m 4s\tremaining: 1m 2s\n",
      "926:\tlearn: 2.1376367\ttotal: 13m 5s\tremaining: 1m 1s\n",
      "927:\tlearn: 2.1376348\ttotal: 13m 6s\tremaining: 1m 1s\n",
      "928:\tlearn: 2.1372377\ttotal: 13m 7s\tremaining: 1m\n",
      "929:\tlearn: 2.1371505\ttotal: 13m 8s\tremaining: 59.3s\n",
      "930:\tlearn: 2.1371485\ttotal: 13m 9s\tremaining: 58.5s\n",
      "931:\tlearn: 2.1368949\ttotal: 13m 9s\tremaining: 57.6s\n",
      "932:\tlearn: 2.1358544\ttotal: 13m 10s\tremaining: 56.8s\n",
      "933:\tlearn: 2.1353570\ttotal: 13m 11s\tremaining: 55.9s\n",
      "934:\tlearn: 2.1346676\ttotal: 13m 12s\tremaining: 55.1s\n",
      "935:\tlearn: 2.1343083\ttotal: 13m 14s\tremaining: 54.3s\n",
      "936:\tlearn: 2.1341560\ttotal: 13m 14s\tremaining: 53.4s\n",
      "937:\tlearn: 2.1336283\ttotal: 13m 15s\tremaining: 52.6s\n",
      "938:\tlearn: 2.1332615\ttotal: 13m 16s\tremaining: 51.7s\n",
      "939:\tlearn: 2.1332318\ttotal: 13m 17s\tremaining: 50.9s\n",
      "940:\tlearn: 2.1326540\ttotal: 13m 18s\tremaining: 50.1s\n",
      "941:\tlearn: 2.1325237\ttotal: 13m 19s\tremaining: 49.2s\n",
      "942:\tlearn: 2.1320839\ttotal: 13m 19s\tremaining: 48.4s\n",
      "943:\tlearn: 2.1320586\ttotal: 13m 20s\tremaining: 47.5s\n",
      "944:\tlearn: 2.1320311\ttotal: 13m 21s\tremaining: 46.7s\n",
      "945:\tlearn: 2.1316885\ttotal: 13m 22s\tremaining: 45.8s\n",
      "946:\tlearn: 2.1316200\ttotal: 13m 23s\tremaining: 45s\n",
      "947:\tlearn: 2.1304508\ttotal: 13m 24s\tremaining: 44.1s\n",
      "948:\tlearn: 2.1296905\ttotal: 13m 25s\tremaining: 43.3s\n",
      "949:\tlearn: 2.1295944\ttotal: 13m 25s\tremaining: 42.4s\n",
      "950:\tlearn: 2.1293679\ttotal: 13m 26s\tremaining: 41.6s\n",
      "951:\tlearn: 2.1293133\ttotal: 13m 27s\tremaining: 40.7s\n",
      "952:\tlearn: 2.1291704\ttotal: 13m 28s\tremaining: 39.9s\n",
      "953:\tlearn: 2.1288670\ttotal: 13m 29s\tremaining: 39s\n",
      "954:\tlearn: 2.1288103\ttotal: 13m 30s\tremaining: 38.2s\n",
      "955:\tlearn: 2.1283617\ttotal: 13m 31s\tremaining: 37.3s\n",
      "956:\tlearn: 2.1276106\ttotal: 13m 32s\tremaining: 36.5s\n",
      "957:\tlearn: 2.1273349\ttotal: 13m 33s\tremaining: 35.6s\n",
      "958:\tlearn: 2.1271933\ttotal: 13m 33s\tremaining: 34.8s\n",
      "959:\tlearn: 2.1268722\ttotal: 13m 34s\tremaining: 33.9s\n",
      "960:\tlearn: 2.1265033\ttotal: 13m 35s\tremaining: 33.1s\n",
      "961:\tlearn: 2.1263917\ttotal: 13m 36s\tremaining: 32.2s\n",
      "962:\tlearn: 2.1263216\ttotal: 13m 37s\tremaining: 31.4s\n",
      "963:\tlearn: 2.1261950\ttotal: 13m 38s\tremaining: 30.6s\n",
      "964:\tlearn: 2.1244510\ttotal: 13m 39s\tremaining: 29.7s\n",
      "965:\tlearn: 2.1240840\ttotal: 13m 40s\tremaining: 28.9s\n",
      "966:\tlearn: 2.1232982\ttotal: 13m 40s\tremaining: 28s\n",
      "967:\tlearn: 2.1230562\ttotal: 13m 41s\tremaining: 27.2s\n",
      "968:\tlearn: 2.1230121\ttotal: 13m 42s\tremaining: 26.3s\n",
      "969:\tlearn: 2.1226144\ttotal: 13m 43s\tremaining: 25.5s\n",
      "970:\tlearn: 2.1210048\ttotal: 13m 44s\tremaining: 24.6s\n",
      "971:\tlearn: 2.1203051\ttotal: 13m 45s\tremaining: 23.8s\n",
      "972:\tlearn: 2.1195744\ttotal: 13m 46s\tremaining: 22.9s\n",
      "973:\tlearn: 2.1190767\ttotal: 13m 47s\tremaining: 22.1s\n",
      "974:\tlearn: 2.1190537\ttotal: 13m 47s\tremaining: 21.2s\n",
      "975:\tlearn: 2.1188353\ttotal: 13m 48s\tremaining: 20.4s\n",
      "976:\tlearn: 2.1177852\ttotal: 13m 49s\tremaining: 19.5s\n",
      "977:\tlearn: 2.1177701\ttotal: 13m 50s\tremaining: 18.7s\n",
      "978:\tlearn: 2.1173869\ttotal: 13m 50s\tremaining: 17.8s\n",
      "979:\tlearn: 2.1170636\ttotal: 13m 51s\tremaining: 17s\n",
      "980:\tlearn: 2.1162516\ttotal: 13m 52s\tremaining: 16.1s\n",
      "981:\tlearn: 2.1156943\ttotal: 13m 53s\tremaining: 15.3s\n",
      "982:\tlearn: 2.1149295\ttotal: 13m 54s\tremaining: 14.4s\n",
      "983:\tlearn: 2.1143205\ttotal: 13m 55s\tremaining: 13.6s\n",
      "984:\tlearn: 2.1142296\ttotal: 13m 56s\tremaining: 12.7s\n",
      "985:\tlearn: 2.1139988\ttotal: 13m 56s\tremaining: 11.9s\n",
      "986:\tlearn: 2.1139030\ttotal: 13m 57s\tremaining: 11s\n",
      "987:\tlearn: 2.1136136\ttotal: 13m 58s\tremaining: 10.2s\n",
      "988:\tlearn: 2.1131725\ttotal: 13m 59s\tremaining: 9.33s\n",
      "989:\tlearn: 2.1131619\ttotal: 13m 59s\tremaining: 8.48s\n",
      "990:\tlearn: 2.1131576\ttotal: 14m\tremaining: 7.64s\n",
      "991:\tlearn: 2.1129454\ttotal: 14m 1s\tremaining: 6.79s\n",
      "992:\tlearn: 2.1126946\ttotal: 14m 3s\tremaining: 5.94s\n",
      "993:\tlearn: 2.1126464\ttotal: 14m 3s\tremaining: 5.09s\n",
      "994:\tlearn: 2.1122614\ttotal: 14m 4s\tremaining: 4.25s\n",
      "995:\tlearn: 2.1121009\ttotal: 14m 5s\tremaining: 3.4s\n",
      "996:\tlearn: 2.1120731\ttotal: 14m 6s\tremaining: 2.55s\n",
      "997:\tlearn: 2.1120717\ttotal: 14m 7s\tremaining: 1.7s\n",
      "998:\tlearn: 2.1120435\ttotal: 14m 7s\tremaining: 849ms\n",
      "999:\tlearn: 2.1116985\ttotal: 14m 8s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_score = model._run(training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_test_feature():\n",
    "    submission = pd.read_csv('C:/data/sample_submission.csv', index_col='seg_id', dtype={\"time_to_failure\": np.float64})\n",
    "    test_data = pd.DataFrame(dtype=np.float64)\n",
    "\n",
    "    for i, segment_id in enumerate(submission.index):\n",
    "        segment = pd.read_csv('C:/data/test/' + segment_id + '.csv')\n",
    "        feature_test = get_failure_times(segment, 150_000, False)\n",
    "        test_data = test_data.append(feature_test, ignore_index=True)\n",
    "        \n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Add statistical summaried to test segments\n",
    "feature_test = generate_test_feature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>abs_mean</th>\n",
       "      <th>abs_std</th>\n",
       "      <th>abs_min</th>\n",
       "      <th>abs_max</th>\n",
       "      <th>q95</th>\n",
       "      <th>q99</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_int_mean1000</th>\n",
       "      <th>std_int_mean1000</th>\n",
       "      <th>min_int_mean1000</th>\n",
       "      <th>max_int_mean1000</th>\n",
       "      <th>q95_int_mean1000</th>\n",
       "      <th>q99_int_mean1000</th>\n",
       "      <th>q05_int_mean1000</th>\n",
       "      <th>q01_int_mean1000</th>\n",
       "      <th>change_abs_int_mean1000</th>\n",
       "      <th>change_rate_int_mean1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.491780000000000</td>\n",
       "      <td>4.893689687028069</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>5.224606666666666</td>\n",
       "      <td>4.102160897639040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.491468319004571</td>\n",
       "      <td>0.231890979668247</td>\n",
       "      <td>3.774</td>\n",
       "      <td>5.495</td>\n",
       "      <td>4.867</td>\n",
       "      <td>5.000</td>\n",
       "      <td>4.099</td>\n",
       "      <td>3.889</td>\n",
       "      <td>74583.596158882588497</td>\n",
       "      <td>5.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.171153333333334</td>\n",
       "      <td>5.922839443206628</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>5.198340000000000</td>\n",
       "      <td>5.045368597304222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.173632821256232</td>\n",
       "      <td>0.230913661347393</td>\n",
       "      <td>3.342</td>\n",
       "      <td>5.009</td>\n",
       "      <td>4.541</td>\n",
       "      <td>4.739</td>\n",
       "      <td>3.790</td>\n",
       "      <td>3.644</td>\n",
       "      <td>74346.833284796943190</td>\n",
       "      <td>5.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.610260000000000</td>\n",
       "      <td>6.946990077490285</td>\n",
       "      <td>-193.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>5.597193333333333</td>\n",
       "      <td>6.179524903483504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.612455413050919</td>\n",
       "      <td>0.247219261166618</td>\n",
       "      <td>3.544</td>\n",
       "      <td>6.234</td>\n",
       "      <td>4.966</td>\n",
       "      <td>5.082</td>\n",
       "      <td>4.215</td>\n",
       "      <td>4.013</td>\n",
       "      <td>74349.464458851696691</td>\n",
       "      <td>6.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.531473333333333</td>\n",
       "      <td>4.114146602958288</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>4.961486666666667</td>\n",
       "      <td>3.583863234509939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.532570767981423</td>\n",
       "      <td>0.224908762860213</td>\n",
       "      <td>3.889</td>\n",
       "      <td>5.446</td>\n",
       "      <td>4.911</td>\n",
       "      <td>5.051</td>\n",
       "      <td>4.184</td>\n",
       "      <td>4.032</td>\n",
       "      <td>74430.046482895355439</td>\n",
       "      <td>5.446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.128340000000000</td>\n",
       "      <td>5.797163636220498</td>\n",
       "      <td>-147.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>5.070900000000000</td>\n",
       "      <td>4.993617202464987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.125805276474654</td>\n",
       "      <td>0.274025292743740</td>\n",
       "      <td>3.357</td>\n",
       "      <td>5.027</td>\n",
       "      <td>4.570</td>\n",
       "      <td>4.870</td>\n",
       "      <td>3.662</td>\n",
       "      <td>3.534</td>\n",
       "      <td>74545.727161125323619</td>\n",
       "      <td>5.027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean                std    min    max           abs_mean  \\\n",
       "0  4.491780000000000  4.893689687028069  -75.0  115.0  5.224606666666666   \n",
       "1  4.171153333333334  5.922839443206628 -140.0  152.0  5.198340000000000   \n",
       "2  4.610260000000000  6.946990077490285 -193.0  248.0  5.597193333333333   \n",
       "3  4.531473333333333  4.114146602958288  -93.0   85.0  4.961486666666667   \n",
       "4  4.128340000000000  5.797163636220498 -147.0  177.0  5.070900000000000   \n",
       "\n",
       "             abs_std  abs_min  abs_max   q95   q99            ...             \\\n",
       "0  4.102160897639040      0.0    115.0  11.0  18.0            ...              \n",
       "1  5.045368597304222      0.0    152.0  11.0  20.0            ...              \n",
       "2  6.179524903483504      0.0    248.0  11.0  20.0            ...              \n",
       "3  3.583863234509939      0.0     93.0  10.0  14.0            ...              \n",
       "4  4.993617202464987      0.0    177.0  10.0  19.0            ...              \n",
       "\n",
       "   mean_int_mean1000   std_int_mean1000  min_int_mean1000  max_int_mean1000  \\\n",
       "0  4.491468319004571  0.231890979668247             3.774             5.495   \n",
       "1  4.173632821256232  0.230913661347393             3.342             5.009   \n",
       "2  4.612455413050919  0.247219261166618             3.544             6.234   \n",
       "3  4.532570767981423  0.224908762860213             3.889             5.446   \n",
       "4  4.125805276474654  0.274025292743740             3.357             5.027   \n",
       "\n",
       "   q95_int_mean1000  q99_int_mean1000  q05_int_mean1000  q01_int_mean1000  \\\n",
       "0             4.867             5.000             4.099             3.889   \n",
       "1             4.541             4.739             3.790             3.644   \n",
       "2             4.966             5.082             4.215             4.013   \n",
       "3             4.911             5.051             4.184             4.032   \n",
       "4             4.570             4.870             3.662             3.534   \n",
       "\n",
       "   change_abs_int_mean1000  change_rate_int_mean1000  \n",
       "0    74583.596158882588497                     5.495  \n",
       "1    74346.833284796943190                     5.009  \n",
       "2    74349.464458851696691                     6.234  \n",
       "3    74430.046482895355439                     5.446  \n",
       "4    74545.727161125323619                     5.027  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_test.head(training_set[:,:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast(model, scaler, test_data):\n",
    "    submission = pd.read_csv('C:/data/sample_submission.csv', index_col='seg_id', dtype={\"time_to_failure\": np.float64})\n",
    "    feature_test = scaler.transform(np.array(test_data))\n",
    "    for i in range(test_data.shape[0]):\n",
    "        submission.time_to_failure[i] = model.predict(feature_test[i, :].reshape(1, -1))\n",
    "\n",
    "    submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, you have scaled test data (feature_test). You should use your model and predict based on feature_test.\n",
    "I do not know what you should use instead of ?\n",
    "In general that should be \"model\", but you use best_score, which I do not know what is it.\n",
    "I think you should rewrite forecast function in some way that works for you.\n",
    "\n",
    "forecast(?, model.scaler, feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "print(type(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CatBoostRegressor(iterations=50, depth=3, learning_rate=0.1, loss_function='RMSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_train = MinMaxScaler().fit_transform(training_set[:, :feature_count])\n",
    "target_train = np.array(training_set[:, feature_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 6.2257314\ttotal: 140ms\tremaining: 6.85s\n",
      "1:\tlearn: 5.7533737\ttotal: 236ms\tremaining: 5.66s\n",
      "2:\tlearn: 5.3318427\ttotal: 332ms\tremaining: 5.2s\n",
      "3:\tlearn: 4.9627914\ttotal: 443ms\tremaining: 5.09s\n",
      "4:\tlearn: 4.6335194\ttotal: 537ms\tremaining: 4.83s\n",
      "5:\tlearn: 4.3457582\ttotal: 633ms\tremaining: 4.64s\n",
      "6:\tlearn: 4.0955349\ttotal: 746ms\tremaining: 4.58s\n",
      "7:\tlearn: 3.8824718\ttotal: 853ms\tremaining: 4.48s\n",
      "8:\tlearn: 3.6954844\ttotal: 956ms\tremaining: 4.35s\n",
      "9:\tlearn: 3.5377996\ttotal: 1.06s\tremaining: 4.24s\n",
      "10:\tlearn: 3.3971562\ttotal: 1.16s\tremaining: 4.1s\n",
      "11:\tlearn: 3.2812390\ttotal: 1.26s\tremaining: 3.99s\n",
      "12:\tlearn: 3.1814719\ttotal: 1.35s\tremaining: 3.86s\n",
      "13:\tlearn: 3.1016186\ttotal: 1.53s\tremaining: 3.94s\n",
      "14:\tlearn: 3.0315589\ttotal: 1.65s\tremaining: 3.84s\n",
      "15:\tlearn: 2.9754280\ttotal: 1.77s\tremaining: 3.75s\n",
      "16:\tlearn: 2.9263106\ttotal: 1.88s\tremaining: 3.64s\n",
      "17:\tlearn: 2.8850409\ttotal: 1.97s\tremaining: 3.51s\n",
      "18:\tlearn: 2.8515726\ttotal: 2.08s\tremaining: 3.39s\n",
      "19:\tlearn: 2.8219240\ttotal: 2.17s\tremaining: 3.26s\n",
      "20:\tlearn: 2.7960221\ttotal: 2.31s\tremaining: 3.2s\n",
      "21:\tlearn: 2.7765081\ttotal: 2.41s\tremaining: 3.07s\n",
      "22:\tlearn: 2.7588753\ttotal: 2.5s\tremaining: 2.94s\n",
      "23:\tlearn: 2.7461603\ttotal: 2.62s\tremaining: 2.84s\n",
      "24:\tlearn: 2.7322163\ttotal: 2.77s\tremaining: 2.77s\n",
      "25:\tlearn: 2.7213941\ttotal: 2.88s\tremaining: 2.66s\n",
      "26:\tlearn: 2.7115779\ttotal: 2.97s\tremaining: 2.53s\n",
      "27:\tlearn: 2.7028432\ttotal: 3.07s\tremaining: 2.41s\n",
      "28:\tlearn: 2.6963730\ttotal: 3.17s\tremaining: 2.3s\n",
      "29:\tlearn: 2.6910318\ttotal: 3.27s\tremaining: 2.18s\n",
      "30:\tlearn: 2.6866222\ttotal: 3.37s\tremaining: 2.06s\n",
      "31:\tlearn: 2.6824969\ttotal: 3.47s\tremaining: 1.95s\n",
      "32:\tlearn: 2.6779526\ttotal: 3.57s\tremaining: 1.84s\n",
      "33:\tlearn: 2.6739135\ttotal: 3.67s\tremaining: 1.73s\n",
      "34:\tlearn: 2.6705278\ttotal: 3.79s\tremaining: 1.62s\n",
      "35:\tlearn: 2.6687883\ttotal: 3.89s\tremaining: 1.51s\n",
      "36:\tlearn: 2.6667038\ttotal: 4s\tremaining: 1.4s\n",
      "37:\tlearn: 2.6648425\ttotal: 4.09s\tremaining: 1.29s\n",
      "38:\tlearn: 2.6621692\ttotal: 4.2s\tremaining: 1.18s\n",
      "39:\tlearn: 2.6597028\ttotal: 4.37s\tremaining: 1.09s\n",
      "40:\tlearn: 2.6583913\ttotal: 4.57s\tremaining: 1s\n",
      "41:\tlearn: 2.6566834\ttotal: 4.71s\tremaining: 897ms\n",
      "42:\tlearn: 2.6552485\ttotal: 4.82s\tremaining: 785ms\n",
      "43:\tlearn: 2.6523630\ttotal: 4.94s\tremaining: 673ms\n",
      "44:\tlearn: 2.6506804\ttotal: 5.07s\tremaining: 563ms\n",
      "45:\tlearn: 2.6488687\ttotal: 5.2s\tremaining: 452ms\n",
      "46:\tlearn: 2.6477622\ttotal: 5.31s\tremaining: 339ms\n",
      "47:\tlearn: 2.6470944\ttotal: 5.42s\tremaining: 226ms\n",
      "48:\tlearn: 2.6458413\ttotal: 5.57s\tremaining: 114ms\n",
      "49:\tlearn: 2.6445285\ttotal: 5.71s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x207003027f0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(feature_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-dd9454e9f67a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mforecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-1cf2d3df5c72>\u001b[0m in \u001b[0;36mforecast\u001b[1;34m(model, scaler, test_data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mforecast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0msubmission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C:/data/sample_submission.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'seg_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"time_to_failure\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mfeature_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0msubmission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_to_failure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    380\u001b[0m             \u001b[0mInput\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mtransformed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \"\"\"\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'scale_'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         X = check_array(X, copy=self.copy, dtype=FLOAT_DTYPES,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This MinMaxScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this method."
     ]
    }
   ],
   "source": [
    "forecast(model, MinMaxScaler(), feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('C:/data/sample_submission.csv', index_col='seg_id', dtype={\"time_to_failure\": np.float64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(feature_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_test_scaled = scaler.transform(np.array(feature_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2624"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_test_scaled.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(feature_test_scaled.shape[0]):\n",
    "    submission.time_to_failure[i] = model.predict(feature_test_scaled[i, :].reshape(1, -1))\n",
    "\n",
    "submission.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
