{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for computation of statistical summaries used to compute failure times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from typing import List, Tuple\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.signal import hilbert\n",
    "from scipy.signal import hann\n",
    "from scipy.signal import convolve\n",
    "\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "def linear_reg(data: pd.core.frame.DataFrame, abs=False):\n",
    "    indexes = np.array(range(len(data)))\n",
    "    arr = np.abs(data.values) if abs else data.values\n",
    "\n",
    "    linear_regression = LinearRegression()\n",
    "    linear_regression.fit(indexes.reshape(-1, 1), arr)\n",
    "    return linear_regression.coef_[0]\n",
    "\n",
    "def get_failure_times(data: pd.core.frame.DataFrame, aggregate_length: int = 150000, include_y: bool = True):\n",
    "    size = len(data)\n",
    "    statistical_summary = pd.DataFrame(dtype=np.float64)\n",
    "    index = 0\n",
    "    for i in range(0, size, aggregate_length):\n",
    "        interval_data = data[i:i + aggregate_length]\n",
    "        add_statistical_summaries(index, statistical_summary, interval_data.iloc[:, 0])\n",
    "        if include_y:\n",
    "            statistical_summary.loc[index, 'time_to_failure'] = interval_data.iloc[-1, 1]\n",
    "        index += 1\n",
    "\n",
    "    return statistical_summary\n",
    "\n",
    "def add_statistical_summaries(index: int, statistical_summary: pd.core.frame.DataFrame, interval_data: pd.core.frame.DataFrame):\n",
    "    statistical_summary.loc[index, 'mean'] = interval_data.mean()\n",
    "    statistical_summary.loc[index, 'std'] = interval_data.std()\n",
    "    statistical_summary.loc[index, 'min'] = interval_data.min()\n",
    "    statistical_summary.loc[index, 'max'] = interval_data.max()\n",
    "    absVals = np.abs(interval_data)\n",
    "\n",
    "    statistical_summary.loc[index, 'abs_mean'] = absVals.mean()\n",
    "    statistical_summary.loc[index, 'abs_std'] = absVals.std()\n",
    "    statistical_summary.loc[index, 'abs_min'] = absVals.min()\n",
    "    statistical_summary.loc[index, 'abs_max'] = absVals.max()\n",
    "    statistical_summary.loc[index, 'q95'] = np.quantile(interval_data, 0.95)\n",
    "    statistical_summary.loc[index, 'q99'] = np.quantile(interval_data, 0.99)\n",
    "    statistical_summary.loc[index, 'q05'] = np.quantile(interval_data, 0.05)\n",
    "    statistical_summary.loc[index, 'q01'] = np.quantile(interval_data, 0.01)\n",
    "\n",
    "    statistical_summary.loc[index, 'std_f50000'] = interval_data[:50000].mean()\n",
    "    statistical_summary.loc[index, 'mean_f50000'] = interval_data[:50000].std()\n",
    "    statistical_summary.loc[index, 'min_f50000'] = interval_data[:50000].min()\n",
    "    statistical_summary.loc[index, 'max_f50000'] = interval_data[:50000].max()\n",
    "    statistical_summary.loc[index, 'std_l50000'] = interval_data[-50000:].mean()\n",
    "    statistical_summary.loc[index, 'mean_l50000'] = interval_data[-50000:].std()\n",
    "    statistical_summary.loc[index, 'min_l50000'] = interval_data[-50000:].min()\n",
    "    statistical_summary.loc[index, 'max_l50000'] = interval_data[-50000:].max()\n",
    "\n",
    "    statistical_summary.loc[index, 'std_first1000'] = interval_data[:1000].mean()\n",
    "    statistical_summary.loc[index, 'mean_first1000'] = interval_data[:1000].std()\n",
    "    statistical_summary.loc[index, 'min_first1000'] = interval_data[:1000].min()\n",
    "    statistical_summary.loc[index, 'max_first1000'] = interval_data[:1000].max()\n",
    "\n",
    "    statistical_summary.loc[index, 'std_last1000'] = interval_data[-1000:].mean()\n",
    "    statistical_summary.loc[index, 'mean_last1000'] = interval_data[-1000:].std()\n",
    "    statistical_summary.loc[index, 'min_last1000'] = interval_data[-1000:].min()\n",
    "    statistical_summary.loc[index, 'max_last1000'] = interval_data[-1000:].max()\n",
    "\n",
    "    statistical_summary.loc[index, 'trend'] = linear_reg(interval_data)\n",
    "    statistical_summary.loc[index, 'trend_abs'] = linear_reg(interval_data, True)\n",
    "\n",
    "    statistical_summary.loc[index, 'count_big'] = len(interval_data[np.abs(interval_data) > 500])\n",
    "    statistical_summary.loc[index, 'hilbert_mean'] = np.abs(hilbert(interval_data)).mean()\n",
    "\n",
    "    hann_window_150 = hann(150)\n",
    "    statistical_summary.loc[index, 'hann_window_mean'] = (convolve(interval_data, hann_window_150, mode='same') / sum(hann_window_150)).mean()\n",
    "\n",
    "    for windows in [10, 100, 1000]:\n",
    "        int_std = interval_data.rolling(windows).std().dropna().values\n",
    "        windows_str = str(windows)\n",
    "\n",
    "        statistical_summary.loc[index, 'mean_int_std' + windows_str] = int_std.mean()\n",
    "        statistical_summary.loc[index, 'std_int_std' + windows_str] = int_std.std()\n",
    "        statistical_summary.loc[index, 'min_int_std' + windows_str] = int_std.min()\n",
    "        statistical_summary.loc[index, 'max_int_std' + windows_str] = int_std.max()\n",
    "        statistical_summary.loc[index, 'q95_int_std' + windows_str] = np.quantile(int_std, 0.95)\n",
    "        statistical_summary.loc[index, 'q99_int_std' + windows_str] = np.quantile(int_std, 0.99)\n",
    "        statistical_summary.loc[index, 'q05_int_std' + windows_str] = np.quantile(int_std, 0.05)\n",
    "        statistical_summary.loc[index, 'q01_int_std' + windows_str] = np.quantile(int_std, 0.01)\n",
    "\n",
    "        statistical_summary.loc[index, 'change_abs_int_std' + windows_str] = np.mean(np.nonzero((np.diff(int_std) / int_std[:-1]))[0])\n",
    "\n",
    "        statistical_summary.loc[index, 'change_rate_int_std' + windows_str] = np.abs(int_std).max()\n",
    "\n",
    "        int_mean = interval_data.rolling(windows).mean().dropna().values\n",
    "\n",
    "        statistical_summary.loc[index, 'mean_int_mean' + windows_str] = int_mean.mean()\n",
    "        statistical_summary.loc[index, 'std_int_mean' + windows_str] = int_mean.std()\n",
    "        statistical_summary.loc[index, 'min_int_mean' + windows_str] = int_mean.min()\n",
    "        statistical_summary.loc[index, 'max_int_mean' + windows_str] = int_mean.max()\n",
    "        statistical_summary.loc[index, 'q95_int_mean' + windows_str] = np.quantile(int_mean, 0.95)\n",
    "        statistical_summary.loc[index, 'q99_int_mean' + windows_str] = np.quantile(int_mean, 0.99)\n",
    "        statistical_summary.loc[index, 'q05_int_mean' + windows_str] = np.quantile(int_mean, 0.05)\n",
    "        statistical_summary.loc[index, 'q01_int_mean' + windows_str] = np.quantile(int_mean, 0.01)\n",
    "\n",
    "        statistical_summary.loc[index, 'change_abs_int_mean' + windows_str] = np.mean(np.nonzero((np.diff(int_mean) / int_mean[:-1]))[0])\n",
    "\n",
    "        statistical_summary.loc[index, 'change_rate_int_mean' + windows_str] = np.abs(int_mean).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
